name: FBGEMMCI

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]

    steps:
    - uses: actions/checkout@v2
    - name: Checkout submodules
      shell: bash
      run: |
        auth_header="$(git config --local --get http.https://github.com/.extraheader)"
        git submodule sync --recursive
        git -c "http.extraheader=$auth_header" -c protocol.version=2 submodule update --init --force --recursive --depth=1

    - name: Get CPU info on Ubuntu
      if: contains(runner.os, 'linux')
      run: |
        cat /proc/cpuinfo

    - name: Get CPU info on macOS
      if: contains(runner.os, 'macOs')
      run: |
        sysctl -a | grep machdep.cpu

    - name: Get env vars
      run: |
        echo GITHUB_WORKFLOW   = $GITHUB_WORKFLOW
        echo HOME              = $HOME
        echo GITHUB_ACTION     = $GITHUB_ACTION
        echo GITHUB_ACTIONS    = $GITHUB_ACTIONS
        echo GITHUB_REPOSITORY = $GITHUB_REPOSITORY
        echo GITHUB_EVENT_NAME = $GITHUB_EVENT_NAME
        echo GITHUB_EVENT_PATH = $GITHUB_EVENT_PATH
        echo GITHUB_WORKSPACE  = $GITHUB_WORKSPACE
        echo GITHUB_SHA        = $GITHUB_SHA
        echo GITHUB_REF        = $GITHUB_REF
        c++ --verbose

    - name: Build static FBGEMM lib
      run: |
        set -e
        mkdir build_static
        cd build_static
        cmake -DUSE_SANITIZER=address -DFBGEMM_LIBRARY_TYPE=static ..
        make

    - name: Test static FBGEMM lib
      if: contains(runner.os, 'linux')   # not run on macos-latest now due to supporting AVX2
      run: |
        set -e
        cd build_static
        ctest

    - name: Build shared FBGEMM lib
      run: |
        set -e
        mkdir build_shared
        cd build_shared
        cmake -DUSE_SANITIZER=address -DFBGEMM_LIBRARY_TYPE=shared ..
        make

    - name: Test shared FBGEMM lib
      if: contains(runner.os, 'linux')   # not run on macos-latest now due to supporting AVX2
      run: |
        set -e
        cd build_shared
        ctest

  build-windows:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [windows-2019]

    steps:
    - uses: actions/checkout@v2
    - name: Checkout submodules
      shell: bash
      run: |
        auth_header="$(git config --local --get http.https://github.com/.extraheader)"
        git submodule sync --recursive
        git -c "http.extraheader=$auth_header" -c protocol.version=2 submodule update --init --force --recursive --depth=1

    - name: Get CPU info on Windows
      shell: cmd
      run: |
        wmic cpu list full

    - name: Build static FBGEMM lib
      shell: cmd
      run: |
        call "C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\VC\Auxiliary\Build\vcvarsall.bat" x64
        echo "INSTALL NINJA:"
        pip install ninja
        which ninja
        mkdir build_static
        cd build_static
        echo "STARTING CMAKE"
        cmake -G Ninja -DFBGEMM_BUILD_BENCHMARKS=OFF -DFBGEMM_LIBRARY_TYPE=static -DCMAKE_BUILD_TYPE=Release -DCMAKE_C_COMPILER="cl.exe" -DCMAKE_CXX_COMPILER="cl.exe" ..
        ninja all
        echo "Build Success"

    - name: Test static FBGEMM lib
      shell: cmd
      run: |
        echo %cd%
        cd build_static
        ctest --rerun-failed --output-on-failure
        if errorlevel 1 exit /b 1

    - name: Build shared FBGEMM lib
      shell: cmd
      run: |
        call "C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\VC\Auxiliary\Build\vcvarsall.bat" x64
        echo "INSTALL NINJA:"
        pip install ninja
        which ninja
        mkdir build_shared
        cd build_shared
        echo "STARTING CMAKE"
        cmake -G Ninja -DFBGEMM_BUILD_BENCHMARKS=OFF -DFBGEMM_LIBRARY_TYPE=shared -DCMAKE_BUILD_TYPE=Release -DCMAKE_C_COMPILER="cl.exe" -DCMAKE_CXX_COMPILER="cl.exe" ..
        ninja all
        if errorlevel 1 exit /b 1

    - name: Test shared FBGEMM lib
      shell: cmd
      run: |
        echo %cd%
        cd build_shared
        set PATH=%PATH%;%cd%;%cd%\asmjit
        echo %PATH%
        ctest
        if errorlevel 1 exit /b 1

  build-bazel:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest]

    steps:
    - uses: actions/checkout@v2
    - name: Checkout submodules
      shell: bash
      run: |
        auth_header="$(git config --local --get http.https://github.com/.extraheader)"
        git submodule sync --recursive
        git -c "http.extraheader=$auth_header" -c protocol.version=2 submodule update --init --force --recursive --depth=1

    - name: Get env vars
      run: |
        echo GITHUB_WORKFLOW   = $GITHUB_WORKFLOW
        echo HOME              = $HOME
        echo GITHUB_ACTION     = $GITHUB_ACTION
        echo GITHUB_ACTIONS    = $GITHUB_ACTIONS
        echo GITHUB_REPOSITORY = $GITHUB_REPOSITORY
        echo GITHUB_EVENT_NAME = $GITHUB_EVENT_NAME
        echo GITHUB_EVENT_PATH = $GITHUB_EVENT_PATH
        echo GITHUB_WORKSPACE  = $GITHUB_WORKSPACE
        echo GITHUB_SHA        = $GITHUB_SHA
        echo GITHUB_REF        = $GITHUB_REF
        c++ --verbose

    - name: Download bazel
      run: |
        set -e
        wget https://github.com/bazelbuild/bazel/releases/download/2.2.0/bazel-2.2.0-linux-x86_64 -O bazel
        # verify content
        echo 'b2f002ea0e6194a181af6ac84cd94bd8dc797722eb2354690bebac92dda233ff bazel' | sha256sum --quiet -c
        chmod +x bazel


    - name: Build FBGEMM with bazel
      run: |
        set -e
        ./bazel build --verbose_explanations --verbose_failures --compilation_mode opt :*

    - name: Test FBGEMM bazel build
      run: |
        set -e
        ./bazel test --compilation_mode opt :*


  build_nvidia_gpu:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-20.04]
        config: [[pip, 11.3], [pip, 11.5], [pip, 11.6], [pip, 11.7], [conda, 11.7]]

    steps:
    - uses: actions/checkout@v2

    - name: Install CUDA
      shell: bash
      if: matrix.config[0] == 'pip'
      run: |
        wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
        sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
        # https://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212772
        wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
        sudo dpkg -i cuda-keyring_1.0-1_all.deb
        # sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub
        sudo add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /"
        sudo apt-get update
        # "11.5 -> 11-5"
        cuda_apt_version=$(echo "${{ matrix.config[1] }}" | sed "s/\./-/")
        sudo apt-get -y install cuda-minimal-build-${cuda_apt_version} cuda-nvrtc-dev-${cuda_apt_version} cuda-nvtx-${cuda_apt_version} cuda-libraries-dev-${cuda_apt_version}
        sudo apt-get -y install libcudnn8-dev

    - name: Install dependencies
      shell: bash
      run: |
        if [ x"${{ matrix.config[0] }}" == x"pip" ]; then
          # pip-based installation
          sudo apt-get update
          sudo apt-get -y install git pip python3-dev
          sudo pip install cmake scikit-build ninja jinja2 numpy hypothesis --no-input
          # Install pytorch built with CUDA 11.3 in all cases
          sudo pip install --pre torch -f https://download.pytorch.org/whl/nightly/cu113/torch_nightly.html
        else
          # conda-based installation
          wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh
          bash ~/miniconda.sh -b -p $HOME/miniconda -u
          eval "$($HOME/miniconda/bin/conda shell.bash hook)"
          cuda_version="${{ matrix.config[1] }}"
          conda install -y pytorch pytorch-cuda="$cuda_version" -c pytorch-nightly -c nvidia
          conda install -y -c conda-forge cudnn
          conda install -y numpy scikit-build jinja2 ninja cmake hypothesis
        fi
    - name: Checkout submodules
      shell: bash
      run: |
        cd fbgemm_gpu
        git submodule sync
        git submodule update --init --recursive

    - name: Build fbgemm_gpu
      shell: bash
      run: |
        cd fbgemm_gpu
        if [ x"${{ matrix.config[0] }}" == x"pip" ]; then
          CUDA_PATH="/usr/local/cuda-${{ matrix.config[1] }}"
          sudo CUDACXX="${CUDA_PATH}/bin/nvcc" python setup.py install -DTORCH_CUDA_ARCH_LIST="6.0"
        else
          eval "$($HOME/miniconda/bin/conda shell.bash hook)"
          python setup.py install -DTORCH_CUDA_ARCH_LIST="6.0"
        fi

    - name: Test fbgemm_gpu installation
      shell: bash
      run: |
        if [ x"${{ matrix.config[0] }}" == x"conda" ]; then
          eval "$($HOME/miniconda/bin/conda shell.bash hook)"
        fi
        cd fbgemm_gpu
        cd test
        python input_combine_test.py -v
        python quantize_ops_test.py -v
        python sparse_ops_test.py -v
        python -c "import fbgemm_gpu"
        python -c "import fbgemm_gpu.split_embedding_codegen_lookup_invokers"

  build_amd_gpu:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-20.04]
        config: [[pip, 5.3]]

    steps:
    - name: Free space
      run: sudo rm -rf /usr/local/android /usr/share/dotnet /usr/local/share/boost /opt/ghc /usr/local/share/chrom* /usr/share/swift /usr/local/julia* /usr/local/lib/android

    - uses: actions/checkout@v2

    - name: Install ROCm
      shell: bash
      run: |
        sudo update-alternatives --install /usr/bin/python python /usr/bin/python3 10
        wget https://repo.radeon.com/amdgpu-install/5.3/ubuntu/focal/amdgpu-install_5.3.50300-1_all.deb
        export DEBIAN_FRONTEND=noninteractive
        sudo apt install -y ./amdgpu-install_5.3.50300-1_all.deb
        amdgpu-install -y --usecase=hiplibsdk,rocm --no-dkms
        sudo rm amdgpu-install_5.3.50300-1_all.deb

    - name: Install dependencies
      shell: bash
      run: |
        sudo apt-get update
        sudo apt-get install -y git pip python3-dev mesa-common-dev clang comgr libopenblas-dev jp intel-mkl-full locales libnuma-dev
        sudo apt-get install -y hipify-clang || true
        sudo apt-get install -y miopen-hip miopen-hip-dev
        sudo pip install cmake scikit-build ninja jinja2 numpy hypothesis --no-input
        sudo apt-get clean
        # Install PyTorch (nightly) as required by fbgemm_gpu
        sudo pip install --pre torch torchvision --extra-index-url https://download.pytorch.org/whl/nightly/rocm5.3/

    - name: Checkout submodules
      shell: bash
      run: |
        cd fbgemm_gpu
        git submodule sync
        git submodule update --init --recursive

    - name: Build fbgemm_gpu
      shell: bash
      run: |
        sudo update-alternatives --install /usr/bin/python python /usr/bin/python3 10
        cd fbgemm_gpu
        # build for MI250 only to save time.
        sudo PYTORCH_ROCM_ARCH=gfx90a python3 setup.py build develop

    - name: Test fbgemm_gpu installation
      shell: bash
      run: |
        cd fbgemm_gpu
        cd test
        python3 input_combine_test.py -v
        python3 quantize_ops_test.py -v
        python3 sparse_ops_test.py -v
        python3 -c "import fbgemm_gpu"
        python3 -c "import fbgemm_gpu.split_embedding_codegen_lookup_invokers"

  test_amd_gpu:
    runs-on: rocm
    strategy:
      matrix:
        os: [ubuntu-latest]

    steps:
    - name: pre-checkout
      shell: bash
      run: |
        if [ -d ${{ github.workspace }} ]
        then
          sudo chown -R $USER:$USER ${{ github.workspace }}
        fi
        sudo add-apt-repository ppa:git-core/ppa
        sudo apt update
        sudo apt -y install --only-upgrade git

    - uses: actions/checkout@v2
      with:
        ref: ${{ github.ref }}
        submodules: 'true'

    - name: build fbgemm_gpu and test
      shell: bash
      run: |
        set -eux
        env
        ls -l
        DOCKER_IMAGE=rocm/pytorch:rocm5.3_ubuntu20.04_py3.7_pytorch_staging_base
        docker pull $DOCKER_IMAGE
        JENKINS_REPO_DIR=fbgemm-private-jenkins
        JENKINS_REPO_DIR_BAREMETAL=$PWD
        JENKINS_REPO_DIR_DOCKER=/workspace/$JENKINS_REPO_DIR
        DOCKER_OPTIONS="\
        --user 0 \
        --network=host \
        --ipc=host \
        --shm-size 16G \
        --group-add video \
        --cap-add=SYS_PTRACE \
        --security-opt seccomp=unconfined \
        --device=/dev/kfd \
        --device=/dev/dri \
        -v $JENKINS_REPO_DIR_BAREMETAL:$JENKINS_REPO_DIR_DOCKER
        "
        docker run $DOCKER_OPTIONS $DOCKER_IMAGE $JENKINS_REPO_DIR_DOCKER/.jenkins/rocm/build_and_test.sh $JENKINS_REPO_DIR_DOCKER

  test_nvidia_gpu:
    uses: pytorch/test-infra/.github/workflows/linux_job.yml@main
    with:
      job-name: cuda 11.7, A10
      runner: linux.g5.4xlarge.nvidia.gpu # A10
      repository: pytorch/fbgemm
      gpu-arch-type: cuda
      gpu-arch-version: 11.7
      timeout: 150
      script: |
        set -x
        # Checkout FBGEMM_GPU
        git submodule update --init

        # Build FBGEMM_GPU with pytorch-nightly
        PYTORCH_CUDA_VERSION="11.7"
        PYTHON_VERSION="3.10"
        bash .github/scripts/build_wheel.bash -v -p "$PYTHON_VERSION" -o fbgemm_gpu_test -P pytorch-nightly -c "$PYTORCH_CUDA_VERSION" -m /opt/conda

        # Test FBGEMM_GPU using a generated wheel file
        WHEEL_PATH="$(ls fbgemm_gpu/dist/*.whl)"
        bash .github/scripts/test_wheel.bash -v -p "$PYTHON_VERSION" -P pytorch-nightly -c "$PYTORCH_CUDA_VERSION" -w "$WHEEL_PATH" -m /opt/conda

  build_cpu_only:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest]

    steps:
    - uses: actions/checkout@v2

    - name: Install dependencies
      shell: bash
      run: |
        sudo apt-get update
        sudo apt-get -y install git pip python3-dev
        sudo pip install cmake scikit-build ninja jinja2 numpy hypothesis --no-input
        # Install PyTorch (nightly) as required by fbgemm_gpu
        sudo pip install --pre torch -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html

    - name: Checkout submodules
      shell: bash
      run: |
        cd fbgemm_gpu
        git submodule sync
        git submodule update --init --recursive

    - name: Build fbgemm_gpu
      shell: bash
      run: |
        cd fbgemm_gpu
        # to avoid "Permission denied" error in '/usr/local/lib/python3.8/dist-packages/' folder
        sudo python setup.py install --cpu_only

    - name: Test fbgemm_gpu cpu-only installation
      shell: bash
      run: |
        cd fbgemm_gpu
        cd test
        python batched_unary_embeddings_test.py -v
        python input_combine_test.py -v
        python layout_transform_ops_test.py -v
        python merge_pooled_embeddings_test.py -v
        python permute_pooled_embedding_modules_test.py -v
        python quantize_ops_test.py -v
        python sparse_ops_test.py -v
