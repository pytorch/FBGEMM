# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

name: FBGEMM_GPU Nightly Build

on:
  # PR Trigger (enabled only for debugging)
  #
  pull_request:
    branches:
      - main

  # Push Trigger (enable to catch errors coming out of multiple merges)
  #
  push:
    branches:
      - main

  # Cron Trigger
  #
  # Based on the Conda page for PyTorch-nightly, the GPU nightly releases appear
  # around 02:30 every day (roughly 2 hours after the CPU releases)
  #
  schedule:
    - cron:  '45 04 * * *'

  # Manual trigger
  #
  workflow_dispatch:

jobs:
  # Build on CPU hosts and upload to GHA
  build_on_cpu:
    runs-on: ${{ matrix.os }}
    defaults:
      run:
        shell: bash
    env:
      PRELUDE: .github/scripts/setup_env.bash
      BUILD_ENV: build_binary
    strategy:
      # Don't fast-fail all the other builds if one of the them fails
      fail-fast: false
      matrix:
        os: [ linux.12xlarge ]
        python-version: [ "3.8", "3.9", "3.10" ]
        cuda-version: [ "11.7.1" ]

    steps:
    - name: Checkout the Repository
      uses: actions/checkout@v3
      with:
        submodules: true

    - name: Display System Info
      run: . $PRELUDE; print_system_info

    - name: Setup Miniconda
      run: |
        . $PRELUDE; setup_miniconda $HOME/miniconda
        echo "${HOME}/miniconda/bin" >> $GITHUB_PATH
        echo "CONDA=${HOME}/miniconda" >> $GITHUB_PATH

    - name: Create Conda Environment
      run: . $PRELUDE; create_conda_environment $BUILD_ENV ${{ matrix.python-version }}

    - name: Install C/C++ Compilers
      run: . $PRELUDE; install_cxx_compiler $BUILD_ENV

    - name: Install Build Tools
      run: . $PRELUDE; install_build_tools $BUILD_ENV

    - name: Install CUDA
      run: . $PRELUDE; install_cuda $BUILD_ENV ${{ matrix.cuda-version }}

    - name: Install PyTorch Nightly
      run: . $PRELUDE; install_pytorch_conda $BUILD_ENV nightly

    - name: Install cuDNN
      run: . $PRELUDE; install_cudnn $BUILD_ENV "$(pwd)/build_only/cudnn" ${{ matrix.cuda-version }}

    - name: Prepare FBGEMM Build
      run: . $PRELUDE; cd fbgemm_gpu; prepare_fbgemm_gpu_build $BUILD_ENV

    - name: Build FBGEMM_GPU Nightly
      run: . $PRELUDE; cd fbgemm_gpu; build_fbgemm_gpu_package $BUILD_ENV fbgemm_gpu_nightly

    - name: Upload Built Wheel as GHA Artifact
      uses: actions/upload-artifact@v3
      with:
        name: fbgemm_gpu_nightly_${{ matrix.python-version }}_cuda${{ matrix.cuda-version }}.whl
        path: fbgemm_gpu/dist/fbgemm_gpu_nightly-*.whl


  # Download the built artifact from GHA, test on GPU, and push to PyPI
  test_on_gpu:
    runs-on: ${{ matrix.os }}
    defaults:
      run:
        shell: bash
    env:
      PRELUDE: .github/scripts/setup_env.bash
      BUILD_ENV: build_binary
    strategy:
      fail-fast: false
      matrix:
        os: [ linux.g5.4xlarge.nvidia.gpu ]
        python-version: [ "3.8", "3.9", "3.10" ]
        cuda-version: [ "11.7.1" ]
    needs: build_on_cpu
    steps:
    - name: Checkout the Repository
      uses: actions/checkout@v3
      with:
        submodules: true

    - name: Display System Info
      run: . $PRELUDE; print_system_info

    - name: Display EC2 Info
      run: . $PRELUDE; print_ec2_info

    - name: Setup Miniconda
      run: |
        . $PRELUDE; setup_miniconda $HOME/miniconda
        echo "${HOME}/miniconda/bin" >> $GITHUB_PATH
        echo "CONDA=${HOME}/miniconda" >> $GITHUB_PATH

    - name: Create Conda Environment
      run: . $PRELUDE; create_conda_environment $BUILD_ENV ${{ matrix.python-version }}

    - name: Install CUDA
      run: . $PRELUDE; install_cuda $BUILD_ENV ${{ matrix.cuda-version }}

    - name: Install PyTorch Nightly
      run: . $PRELUDE; install_pytorch_conda $BUILD_ENV nightly

    - name: Prepare FBGEMM Build
      run: . $PRELUDE; cd fbgemm_gpu; prepare_fbgemm_gpu_build $BUILD_ENV

    - name: Download Wheel Artifact from GHA
      uses: actions/download-artifact@v3
      with:
        name: fbgemm_gpu_nightly_${{ matrix.python-version }}_cuda${{ matrix.cuda-version }}.whl

    - name: Display structure of downloaded files
      run: ls -R

    - name: Install FBGEMM_GPU Nightly
      run: |
        rm -rf dist
        conda run -n $BUILD_ENV \
          python -m pip install *.whl

    - name: Test FBGEMM_GPU Installation
      shell: bash
      run: |
        conda run -n $BUILD_ENV \
          python -c "import fbgemm_gpu"

    - name: Test with PyTest
      # Remove this line when we fixed all the unit tests
      continue-on-error: true
      run: |
        conda run -n $BUILD_ENV \
          python -m pip install pytest
        # The tests with single CPU core on a less powerful testing GPU in GHA
        # can take 5 hours.
        timeout 600s conda run -n $BUILD_ENV \
          python -m pytest -v -s -W ignore::pytest.PytestCollectionWarning --continue-on-collection-errors

    - name: Push FBGEMM_GPU Binary to PYPI
      if: ${{ github.event_name != 'pull_request' && github.event_name != 'push' }}
      env:
        PYPI_TOKEN: ${{ secrets.PYPI_TOKEN }}
      run: . $PRELUDE; publish_to_pypi $BUILD_ENV fbgemm_gpu_nightly-*.whl "$PYPI_TOKEN"
