# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

name: FBGEMM_GPU CI

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build_nvidia_gpu:
    if: ${{ false }}  # Disable the job for now
    runs-on: ${{ matrix.os }}
    defaults:
      run:
        shell: bash
    env:
      PRELUDE: .github/scripts/setup_env.bash
      BUILD_ENV: build_binary
    strategy:
      # Don't fast-fail all the other builds if one of the them fails
      fail-fast: false
      matrix:
        os: [ ubuntu-20.04 ]
        # PyTorch has dropped support for CUDA 11.6
        cuda-version: [ 11.7.1 ]

    steps:
    - name: Checkout the Repository
      uses: actions/checkout@v3
      with:
        submodules: true

    - name: Display System Info
      run: . $PRELUDE; print_system_info

    - name: Setup Miniconda
      run: |
        . $PRELUDE; setup_miniconda $HOME/miniconda
        echo "${HOME}/miniconda/bin" >> $GITHUB_PATH
        echo "CONDA=${HOME}/miniconda" >> $GITHUB_PATH

    - name: Create Conda Environment
      run: . $PRELUDE; create_conda_environment $BUILD_ENV 3.8

    # - name: Install C/C++ Compilers
    #   run: . $PRELUDE; install_cxx_compiler $BUILD_ENV

    - name: Install Build Tools
      run: . $PRELUDE; install_build_tools $BUILD_ENV

    - name: Install CUDA
      run: . $PRELUDE; install_cuda $BUILD_ENV "${{ matrix.cuda-version }}"

    - name: Install PyTorch
      run:  . $PRELUDE; install_pytorch_pip $BUILD_ENV nightly cuda "${{ matrix.cuda-version }}"

    - name: Install cuDNN
      run: . $PRELUDE; install_cudnn $BUILD_ENV "$(pwd)/build_only/cudnn" "${{ matrix.cuda-version }}"

    - name: Prepare FBGEMM Build
      run: . $PRELUDE; cd fbgemm_gpu; prepare_fbgemm_gpu_build $BUILD_ENV

    - name: Build and Install FBGEMM_GPU
      run: . $PRELUDE; cd fbgemm_gpu; build_fbgemm_gpu_install $BUILD_ENV

    - name: Test FBGEMM_GPU installation
      shell: bash
      run: |
        . $PRELUDE;
        cd fbgemm_gpu/test
        print_exec conda run -n $BUILD_ENV python input_combine_test.py -v
        print_exec conda run -n $BUILD_ENV python quantize_ops_test.py -v
        print_exec conda run -n $BUILD_ENV python sparse_ops_test.py -v
        conda run -n $BUILD_ENV python -c "import fbgemm_gpu"
        conda run -n $BUILD_ENV python -c "import fbgemm_gpu.split_embedding_codegen_lookup_invokers"

  # build_nvidia_gpu:
  #   runs-on: ${{ matrix.os }}
  #   strategy:
  #     matrix:
  #       os: [ubuntu-20.04]
  #       config: [[pip, 11.3], [pip, 11.5], [pip, 11.6], [pip, 11.7], [conda, 11.7.1]]

  #   steps:
  #   - uses: actions/checkout@v3

  #   - name: Install CUDA
  #     shell: bash
  #     if: matrix.config[0] == 'pip'
  #     run: |
  #       wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
  #       sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
  #       # https://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212772
  #       wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
  #       sudo dpkg -i cuda-keyring_1.0-1_all.deb
  #       # sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub
  #       sudo add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /"
  #       sudo apt-get update
  #       # "11.5 -> 11-5"
  #       cuda_apt_version=$(echo "${{ matrix.config[1] }}" | sed "s/\./-/")
  #       sudo apt-get -y install cuda-minimal-build-${cuda_apt_version} cuda-nvrtc-dev-${cuda_apt_version} cuda-nvtx-${cuda_apt_version} cuda-libraries-dev-${cuda_apt_version}
  #       sudo apt-get -y install libcudnn8-dev

  #   - name: Install dependencies
  #     shell: bash
  #     run: |
  #       if [ x"${{ matrix.config[0] }}" == x"pip" ]; then
  #         # pip-based installation
  #         sudo apt-get update
  #         sudo apt-get -y install git pip python3-dev
  #         sudo pip install cmake scikit-build ninja jinja2 numpy hypothesis --no-input
  #         # Install pytorch built with CUDA 11.3 in all cases
  #         sudo pip install --pre torch -f https://download.pytorch.org/whl/nightly/cu113/torch_nightly.html
  #       else
  #         # conda-based installation
  #         wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh
  #         bash ~/miniconda.sh -b -p $HOME/miniconda -u
  #         eval "$($HOME/miniconda/bin/conda shell.bash hook)"
  #         cuda_version="${{ matrix.config[1] }}"
  #         conda install -y pytorch cuda -c pytorch-nightly -c "nvidia/label/cuda-${cuda_version}"
  #         conda install -y -c conda-forge cudnn
  #         conda install -y numpy scikit-build jinja2 ninja cmake hypothesis
  #       fi
  #   - name: Checkout submodules
  #     shell: bash
  #     run: |
  #       cd fbgemm_gpu
  #       git submodule sync
  #       git submodule update --init --recursive

  #   - name: Build fbgemm_gpu
  #     shell: bash
  #     run: |
  #       cd fbgemm_gpu
  #       if [ x"${{ matrix.config[0] }}" == x"pip" ]; then
  #         CUDA_PATH="/usr/local/cuda-${{ matrix.config[1] }}"
  #         sudo CUDACXX="${CUDA_PATH}/bin/nvcc" python setup.py install -DTORCH_CUDA_ARCH_LIST="6.0"
  #       else
  #         eval "$($HOME/miniconda/bin/conda shell.bash hook)"
  #         python setup.py install -DTORCH_CUDA_ARCH_LIST="6.0"
  #       fi

  #   - name: Test fbgemm_gpu installation
  #     shell: bash
  #     run: |
  #       if [ x"${{ matrix.config[0] }}" == x"conda" ]; then
  #         eval "$($HOME/miniconda/bin/conda shell.bash hook)"
  #       fi
  #       cd fbgemm_gpu
  #       cd test
  #       python input_combine_test.py -v
  #       python quantize_ops_test.py -v
  #       python sparse_ops_test.py -v
  #       python -c "import fbgemm_gpu"
  #       python -c "import fbgemm_gpu.split_embedding_codegen_lookup_invokers"

  build_amd_gpu:
    if: ${{ false }}  # Disable the job for now
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-20.04]
        config: [[pip, 5.3]]

    steps:
    - name: Free space
      run: sudo rm -rf /usr/local/android /usr/share/dotnet /usr/local/share/boost /opt/ghc /usr/local/share/chrom* /usr/share/swift /usr/local/julia* /usr/local/lib/android

    - uses: actions/checkout@v3

    - name: Install ROCm
      shell: bash
      run: |
        sudo update-alternatives --install /usr/bin/python python /usr/bin/python3 10
        wget https://repo.radeon.com/amdgpu-install/5.3/ubuntu/focal/amdgpu-install_5.3.50300-1_all.deb
        export DEBIAN_FRONTEND=noninteractive
        sudo apt install -y ./amdgpu-install_5.3.50300-1_all.deb
        amdgpu-install -y --usecase=hiplibsdk,rocm --no-dkms
        sudo rm amdgpu-install_5.3.50300-1_all.deb

    - name: Install dependencies
      shell: bash
      run: |
        sudo apt-get update
        sudo apt-get install -y git pip python3-dev mesa-common-dev clang comgr libopenblas-dev jp intel-mkl-full locales libnuma-dev
        sudo apt-get install -y hipify-clang || true
        sudo apt-get install -y miopen-hip miopen-hip-dev
        sudo pip install cmake scikit-build ninja jinja2 numpy hypothesis --no-input
        sudo apt-get clean
        # Install PyTorch (nightly) as required by fbgemm_gpu
        sudo pip install --pre torch torchvision --extra-index-url https://download.pytorch.org/whl/nightly/rocm5.3/

    - name: Checkout submodules
      shell: bash
      run: |
        cd fbgemm_gpu
        git submodule sync
        git submodule update --init --recursive

    - name: Build fbgemm_gpu
      shell: bash
      run: |
        sudo update-alternatives --install /usr/bin/python python /usr/bin/python3 10
        cd fbgemm_gpu
        # build for MI250 only to save time.
        sudo PYTORCH_ROCM_ARCH=gfx90a python3 setup.py build develop

    - name: Test fbgemm_gpu installation
      shell: bash
      run: |
        cd fbgemm_gpu
        cd test
        python3 input_combine_test.py -v
        python3 quantize_ops_test.py -v
        python3 sparse_ops_test.py -v
        python3 -c "import fbgemm_gpu"
        python3 -c "import fbgemm_gpu.split_embedding_codegen_lookup_invokers"

  test_amd_gpu:
    if: ${{ false }}  # Disable the job for now
    runs-on: rocm
    strategy:
      matrix:
        os: [ubuntu-latest]

    steps:
    - name: pre-checkout
      shell: bash
      run: |
        if [ -d ${{ github.workspace }} ]
        then
          sudo chown -R $USER:$USER ${{ github.workspace }}
        fi
        sudo add-apt-repository ppa:git-core/ppa
        sudo apt update
        sudo apt -y install --only-upgrade git

    - uses: actions/checkout@v3
      with:
        ref: ${{ github.ref }}
        submodules: 'true'

    - name: build fbgemm_gpu and test
      shell: bash
      run: |
        set -eux
        env
        ls -l
        DOCKER_IMAGE=rocm/pytorch:rocm5.4_ubuntu20.04_py3.8_pytorch_staging_base
        docker pull $DOCKER_IMAGE
        JENKINS_REPO_DIR=fbgemm-private-jenkins
        JENKINS_REPO_DIR_BAREMETAL=$PWD
        JENKINS_REPO_DIR_DOCKER=/workspace/$JENKINS_REPO_DIR
        DOCKER_OPTIONS="\
        --user 0 \
        --network=host \
        --ipc=host \
        --shm-size 16G \
        --group-add video \
        --cap-add=SYS_PTRACE \
        --security-opt seccomp=unconfined \
        --device=/dev/kfd \
        --device=/dev/dri \
        -v $JENKINS_REPO_DIR_BAREMETAL:$JENKINS_REPO_DIR_DOCKER
        "
        docker run $DOCKER_OPTIONS $DOCKER_IMAGE $JENKINS_REPO_DIR_DOCKER/.jenkins/rocm/build_and_test.sh $JENKINS_REPO_DIR_DOCKER

  test_nvidia_gpu:
    if: ${{ false }}  # Disable the job for now
    uses: pytorch/test-infra/.github/workflows/linux_job.yml@main
    with:
      job-name: cuda 11.7, A10
      runner: linux.g5.4xlarge.nvidia.gpu # A10
      repository: pytorch/fbgemm
      gpu-arch-type: cuda
      gpu-arch-version: 11.7
      timeout: 150
      script: |
        set -x
        # Checkout FBGEMM_GPU
        git submodule update --init

        # Build FBGEMM_GPU with pytorch-nightly
        CUDA_VERSION="11.7.1"
        PYTHON_VERSION="3.10"
        bash .github/scripts/build_wheel.bash -v -p "$PYTHON_VERSION" -o fbgemm_gpu_test -P pytorch-nightly -c "$CUDA_VERSION" -m /opt/conda

        # Test FBGEMM_GPU using a generated wheel file
        WHEEL_PATH="$(ls fbgemm_gpu/dist/*.whl)"
        bash .github/scripts/test_wheel.bash -v -p "$PYTHON_VERSION" -P pytorch-nightly -c "$CUDA_VERSION" -w "$WHEEL_PATH" -m /opt/conda

  build_cpu_only:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest]

    steps:
    - uses: actions/checkout@v3

    - name: Install dependencies
      shell: bash
      run: |
        sudo apt-get update
        sudo apt-get -y install git pip python3-dev
        sudo pip install cmake scikit-build ninja jinja2 numpy hypothesis --no-input
        # Install PyTorch (nightly) as required by fbgemm_gpu
        sudo pip install --pre torch -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html

    - name: Checkout submodules
      shell: bash
      run: |
        cd fbgemm_gpu
        git submodule sync
        git submodule update --init --recursive

    - name: Build fbgemm_gpu
      shell: bash
      run: |
        cd fbgemm_gpu
        # to avoid "Permission denied" error in '/usr/local/lib/python3.8/dist-packages/' folder
        sudo python setup.py install --cpu_only

    - name: Test fbgemm_gpu cpu-only installation
      shell: bash
      run: |
        cd fbgemm_gpu
        cd test
        python batched_unary_embeddings_test.py -v
        python input_combine_test.py -v
        python layout_transform_ops_test.py -v
        python merge_pooled_embeddings_test.py -v
        python permute_pooled_embedding_modules_test.py -v
        python quantize_ops_test.py -v
        python sparse_ops_test.py -v
