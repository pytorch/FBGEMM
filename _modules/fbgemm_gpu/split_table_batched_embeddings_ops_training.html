


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>fbgemm_gpu.split_table_batched_embeddings_ops_training &mdash; FBGEMM 0.6.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch">
                  <span class="dropdown-title">ExecuTorch</span>
                </a>
              </div>
            </div>  
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  0.6
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">General Info</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../general/Contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../general/documentation/Overview.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../general/ContactUs.html">Contact Us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../general/License.html">License</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm-development/BuildInstructions.html">Build Instructions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM_GPU Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-development/BuildInstructions.html">Build Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-development/InstallationInstructions.html">Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-development/TestInstructions.html">Test Instructions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM_GPU Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-overview/jagged-tensor-ops/JaggedTensorOps.html">Jagged Tensor Operators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm-cpp-api/QuantUtils.html">Quantization Utilities</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM_GPU C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-cpp-api/sparse_ops.html">Sparse Data Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-cpp-api/quantize_ops.html">Quantization Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-cpp-api/merge_pooled_embeddings.html">Pooled Embeddings Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-cpp-api/split_table_batched_embeddings.html">Table Batched Embedding Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-cpp-api/jagged_tensor_ops.html">Jagged Tensor Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-cpp-api/memory_utils.html">CUDA Memory Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-cpp-api/input_combine.html">Combine Input Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-cpp-api/layout_transform_ops.html">Layout Transformation Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-cpp-api/embedding_ops.html">Embedding Operators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM_GPU Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-python-api/table_batched_embedding_ops.html">Table Batched Embedding (TBE) Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fbgemm_gpu-python-api/jagged_tensor_ops.html">Jagged Tensor Operators</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">Module code</a> &gt;</li>
        
      <li>fbgemm_gpu.split_table_batched_embeddings_ops_training</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for fbgemm_gpu.split_table_batched_embeddings_ops_training</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the BSD-style license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="c1"># pyre-ignore-all-errors[56]</span>

<span class="kn">import</span> <span class="nn">enum</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">accumulate</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">log2</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>  <span class="c1"># usort:skip</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Tensor</span>  <span class="c1"># usort:skip</span>

<span class="kn">import</span> <span class="nn">fbgemm_gpu.split_embedding_codegen_lookup_invokers</span> <span class="k">as</span> <span class="nn">invokers</span>
<span class="kn">from</span> <span class="nn">fbgemm_gpu.runtime_monitor</span> <span class="kn">import</span> <span class="n">TBEStatsReporter</span><span class="p">,</span> <span class="n">TBEStatsReporterConfig</span>
<span class="kn">from</span> <span class="nn">fbgemm_gpu.split_embedding_configs</span> <span class="kn">import</span> <span class="n">EmbOptimType</span> <span class="k">as</span> <span class="n">OptimType</span><span class="p">,</span> <span class="n">SparseType</span>
<span class="kn">from</span> <span class="nn">fbgemm_gpu.split_table_batched_embeddings_ops_common</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BoundsCheckMode</span><span class="p">,</span>
    <span class="n">CacheAlgorithm</span><span class="p">,</span>
    <span class="n">CacheState</span><span class="p">,</span>
    <span class="n">construct_cache_state</span><span class="p">,</span>
    <span class="n">EmbeddingLocation</span><span class="p">,</span>
    <span class="n">MAX_PREFETCH_DEPTH</span><span class="p">,</span>
    <span class="n">PoolingMode</span><span class="p">,</span>
    <span class="n">RecordCacheMetrics</span><span class="p">,</span>
    <span class="n">SplitState</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">hip</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">load_library</span><span class="p">(</span>
            <span class="s2">&quot;//deeplearning/fbgemm/fbgemm_gpu/codegen:embedding_ops_hip_training&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">load_library</span><span class="p">(</span>
            <span class="s2">&quot;//deeplearning/fbgemm/fbgemm_gpu/codegen:embedding_ops_cuda_training&quot;</span>
        <span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">load_library</span><span class="p">(</span>
        <span class="s2">&quot;//deeplearning/fbgemm/fbgemm_gpu/codegen:embedding_ops_cpu_training&quot;</span>
    <span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="n">DEFAULT_ASSOC</span> <span class="o">=</span> <span class="mi">32</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">hip</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">64</span>
<span class="n">INT8_EMB_ROW_DIM_OFFSET</span> <span class="o">=</span> <span class="mi">8</span>


<span class="k">class</span> <span class="nc">DoesNotHavePrefix</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
    <span class="k">pass</span>


<span class="k">class</span> <span class="nc">ComputeDevice</span><span class="p">(</span><span class="n">enum</span><span class="o">.</span><span class="n">IntEnum</span><span class="p">):</span>
    <span class="n">CPU</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">CUDA</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">MTIA</span> <span class="o">=</span> <span class="mi">2</span>


<span class="k">class</span> <span class="nc">WeightDecayMode</span><span class="p">(</span><span class="n">enum</span><span class="o">.</span><span class="n">IntEnum</span><span class="p">):</span>
    <span class="n">NONE</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">L2</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">DECOUPLE</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">COUNTER</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">COWCLIP</span> <span class="o">=</span> <span class="mi">4</span>


<span class="k">class</span> <span class="nc">CounterWeightDecayMode</span><span class="p">(</span><span class="n">enum</span><span class="o">.</span><span class="n">IntEnum</span><span class="p">):</span>
    <span class="n">NONE</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">L2</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">DECOUPLE</span> <span class="o">=</span> <span class="mi">2</span>


<span class="k">class</span> <span class="nc">LearningRateMode</span><span class="p">(</span><span class="n">enum</span><span class="o">.</span><span class="n">IntEnum</span><span class="p">):</span>
    <span class="n">EQUAL</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">TAIL_ID_LR_INCREASE</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">TAIL_ID_LR_DECREASE</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">COUNTER_SGD</span> <span class="o">=</span> <span class="mi">2</span>


<span class="k">class</span> <span class="nc">GradSumDecay</span><span class="p">(</span><span class="n">enum</span><span class="o">.</span><span class="n">IntEnum</span><span class="p">):</span>
    <span class="n">NO_DECAY</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">CTR_DECAY</span> <span class="o">=</span> <span class="mi">0</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">TailIdThreshold</span><span class="p">:</span>
    <span class="n">val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">is_ratio</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">CounterBasedRegularizationDefinition</span><span class="p">:</span>
    <span class="n">counter_weight_decay_mode</span><span class="p">:</span> <span class="n">CounterWeightDecayMode</span> <span class="o">=</span> <span class="n">CounterWeightDecayMode</span><span class="o">.</span><span class="n">NONE</span>
    <span class="n">counter_halflife</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">adjustment_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">adjustment_ub</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">learning_rate_mode</span><span class="p">:</span> <span class="n">LearningRateMode</span> <span class="o">=</span> <span class="n">LearningRateMode</span><span class="o">.</span><span class="n">EQUAL</span>
    <span class="n">grad_sum_decay</span><span class="p">:</span> <span class="n">GradSumDecay</span> <span class="o">=</span> <span class="n">GradSumDecay</span><span class="o">.</span><span class="n">NO_DECAY</span>
    <span class="n">tail_id_threshold</span><span class="p">:</span> <span class="n">TailIdThreshold</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">TailIdThreshold</span><span class="p">)</span>
    <span class="n">max_counter_update_freq</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">CowClipDefinition</span><span class="p">:</span>
    <span class="n">counter_weight_decay_mode</span><span class="p">:</span> <span class="n">CounterWeightDecayMode</span> <span class="o">=</span> <span class="n">CounterWeightDecayMode</span><span class="o">.</span><span class="n">NONE</span>
    <span class="n">counter_halflife</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">weight_norm_coefficient</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">lower_bound</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>


<span class="k">def</span> <span class="nf">construct_split_state</span><span class="p">(</span>
    <span class="n">embedding_specs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">EmbeddingLocation</span><span class="p">,</span> <span class="n">ComputeDevice</span><span class="p">]],</span>
    <span class="n">rowwise</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">cacheable</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">precision</span><span class="p">:</span> <span class="n">SparseType</span> <span class="o">=</span> <span class="n">SparseType</span><span class="o">.</span><span class="n">FP32</span><span class="p">,</span>
    <span class="n">int8_emb_row_dim_offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">INT8_EMB_ROW_DIM_OFFSET</span><span class="p">,</span>
    <span class="n">placement</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EmbeddingLocation</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SplitState</span><span class="p">:</span>
    <span class="n">placements</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">EmbeddingLocation</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">offsets</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">dev_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">host_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">uvm_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">num_embeddings</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">location</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">embedding_specs</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">embedding_dim</span> <span class="o">%</span> <span class="mi">4</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;embedding_dim must be a multiple of 4, but got </span><span class="si">{</span><span class="n">embedding_dim</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">precision</span> <span class="o">==</span> <span class="n">SparseType</span><span class="o">.</span><span class="n">INT8</span><span class="p">:</span>
            <span class="n">embedding_dim</span> <span class="o">+=</span> <span class="n">int8_emb_row_dim_offset</span>
        <span class="n">state_size</span> <span class="o">=</span> <span class="n">num_embeddings</span> <span class="o">*</span> <span class="n">embedding_dim</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">rowwise</span> <span class="k">else</span> <span class="n">num_embeddings</span>
        <span class="n">location</span> <span class="o">=</span> <span class="n">placement</span> <span class="k">if</span> <span class="n">placement</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">location</span>
        <span class="k">if</span> <span class="n">location</span> <span class="o">==</span> <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">HOST</span><span class="p">:</span>
            <span class="n">placements</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">HOST</span><span class="p">)</span>
            <span class="n">offsets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">host_size</span><span class="p">)</span>
            <span class="n">host_size</span> <span class="o">+=</span> <span class="n">state_size</span>
        <span class="c1"># If table is on device, then opimtizer is on device.</span>
        <span class="c1"># If table is managed, then if optimizer state is rowwise, optimizer is on device, otherwise optimizer is managed.</span>
        <span class="k">elif</span> <span class="n">location</span> <span class="o">==</span> <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">DEVICE</span> <span class="ow">or</span> <span class="n">rowwise</span><span class="p">:</span>
            <span class="n">placements</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">offsets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dev_size</span><span class="p">)</span>
            <span class="n">dev_size</span> <span class="o">+=</span> <span class="n">state_size</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">cacheable</span> <span class="ow">and</span> <span class="n">location</span> <span class="o">==</span> <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">MANAGED_CACHING</span><span class="p">:</span>
                <span class="n">placements</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">MANAGED_CACHING</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">placements</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">MANAGED</span><span class="p">)</span>
            <span class="n">offsets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">uvm_size</span><span class="p">)</span>
            <span class="n">uvm_size</span> <span class="o">+=</span> <span class="n">state_size</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">placements</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">offsets</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">SplitState</span><span class="p">(</span>
        <span class="n">dev_size</span><span class="o">=</span><span class="n">dev_size</span><span class="p">,</span>
        <span class="n">host_size</span><span class="o">=</span><span class="n">host_size</span><span class="p">,</span>
        <span class="n">uvm_size</span><span class="o">=</span><span class="n">uvm_size</span><span class="p">,</span>
        <span class="n">placements</span><span class="o">=</span><span class="n">placements</span><span class="p">,</span>
        <span class="n">offsets</span><span class="o">=</span><span class="n">offsets</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">apply_split_helper</span><span class="p">(</span>
    <span class="n">persistent_state_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="kc">None</span><span class="p">],</span>
    <span class="n">set_attr_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span>
        <span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">EmbeddingLocation</span><span class="p">]]],</span> <span class="kc">None</span>
    <span class="p">],</span>
    <span class="n">current_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="n">use_cpu</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">feature_table_map</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">split</span><span class="p">:</span> <span class="n">SplitState</span><span class="p">,</span>
    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">],</span>
    <span class="n">enforce_hbm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">make_dev_param</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">dev_reshape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">set_attr_fn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_physical_placements&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">.</span><span class="n">placements</span><span class="p">)</span>
    <span class="n">set_attr_fn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_physical_offsets&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">.</span><span class="n">offsets</span><span class="p">)</span>

    <span class="n">offsets</span> <span class="o">=</span> <span class="p">[</span><span class="n">split</span><span class="o">.</span><span class="n">offsets</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">feature_table_map</span><span class="p">]</span>
    <span class="n">placements</span> <span class="o">=</span> <span class="p">[</span><span class="n">split</span><span class="o">.</span><span class="n">placements</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">feature_table_map</span><span class="p">]</span>
    <span class="n">persistent_state_fn</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_offsets&quot;</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">offsets</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">persistent_state_fn</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_placements&quot;</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">placements</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">split</span><span class="o">.</span><span class="n">dev_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">dev_buffer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="n">split</span><span class="o">.</span><span class="n">dev_size</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">current_device</span><span class="p">,</span>
            <span class="c1"># pyre-fixme[6]</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">dev_buffer</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">dev_buffer</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">dev_reshape</span><span class="p">)</span> <span class="k">if</span> <span class="n">dev_reshape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">dev_buffer</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># pyre-fixme[6]</span>
        <span class="n">dev_buffer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">make_dev_param</span><span class="p">:</span>
        <span class="n">set_attr_fn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_dev&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">dev_buffer</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">persistent_state_fn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_dev&quot;</span><span class="p">,</span> <span class="n">dev_buffer</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">split</span><span class="o">.</span><span class="n">host_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
            <span class="n">persistent_state_fn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_host&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="n">split</span><span class="o">.</span><span class="n">host_size</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">current_device</span><span class="p">,</span>
                    <span class="c1"># pyre-fixme[6]: Expected `Optional[Type[torch._dtype]]` for</span>
                    <span class="c1">#  3rd param but got `Type[Type[torch._dtype]]`.</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">set_attr_fn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_host&quot;</span><span class="p">,</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                        <span class="n">split</span><span class="o">.</span><span class="n">host_size</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">current_device</span><span class="p">,</span>
                        <span class="c1"># pyre-fixme[6]: Expected `Optional[Type[torch._dtype]]`</span>
                        <span class="c1">#  for 3rd param but got `Type[Type[torch._dtype]]`.</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">),</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">persistent_state_fn</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_host&quot;</span><span class="p">,</span>
            <span class="c1"># pyre-fixme[6]: For 3rd param expected `dtype` but got `Type[dtype]`.</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">split</span><span class="o">.</span><span class="n">uvm_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">use_cpu</span>
        <span class="k">if</span> <span class="n">enforce_hbm</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Enforce hbm for the cache location&quot;</span><span class="p">)</span>
            <span class="n">persistent_state_fn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_uvm&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="n">split</span><span class="o">.</span><span class="n">uvm_size</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">current_device</span><span class="p">,</span>
                    <span class="c1"># pyre-fixme[6]: Expected `Optional[Type[torch._dtype]]` for</span>
                    <span class="c1">#  3rd param but got `Type[Type[torch._dtype]]`.</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">persistent_state_fn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_uvm&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="n">split</span><span class="o">.</span><span class="n">uvm_size</span><span class="p">,</span>
                    <span class="n">out</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">new_managed_tensor</span><span class="p">(</span>
                        <span class="c1"># pyre-fixme[6]: Expected `Optional[Type[torch._dtype]]`</span>
                        <span class="c1">#  for 3rd param but got `Type[Type[torch._dtype]]`.</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
                        <span class="p">[</span><span class="n">split</span><span class="o">.</span><span class="n">uvm_size</span><span class="p">],</span>
                    <span class="p">),</span>
                <span class="p">),</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">persistent_state_fn</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_uvm&quot;</span><span class="p">,</span>
            <span class="c1"># pyre-fixme[6]: For 3rd param expected `dtype` but got `Type[dtype]`.</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
        <span class="p">)</span>


<span class="c1"># pyre-fixme[13]: Attribute `uvm_cache_stats` is never initialized.</span>
<span class="c1"># pyre-fixme[13]: Attribute `local_uvm_cache_stats` is never initialized.</span>
<div class="viewcode-block" id="SplitTableBatchedEmbeddingBagsCodegen"><a class="viewcode-back" href="../../fbgemm_gpu-python-api/table_batched_embedding_ops.html#fbgemm_gpu.split_table_batched_embeddings_ops.SplitTableBatchedEmbeddingBagsCodegen">[docs]</a><span class="k">class</span> <span class="nc">SplitTableBatchedEmbeddingBagsCodegen</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Table Batched Embedding (TBE) operator.  Please see</span>
<span class="sd">    docs/table_batched_embedding_ops.py for the extended documentation.</span>

<span class="sd">    Multiple sparse features can share one embedding table.</span>
<span class="sd">    &#39;feature_table_map&#39; specifies the feature-table mapping.</span>
<span class="sd">    T:  number of logical tables</span>
<span class="sd">    T_: number of physical tables</span>
<span class="sd">    T &gt;= T_</span>

<span class="sd">    For supported optimizer hyperparams, see inline comments below</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">embedding_specs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">EmbeddingLocation</span><span class="p">,</span> <span class="n">ComputeDevice</span><span class="p">]]</span>
    <span class="n">optimizer_args</span><span class="p">:</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_args</span><span class="o">.</span><span class="n">OptimizerArgs</span>
    <span class="n">lxu_cache_locations_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="n">lxu_cache_locations_empty</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">timesteps_prefetched</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="n">record_cache_metrics</span><span class="p">:</span> <span class="n">RecordCacheMetrics</span>
    <span class="n">uvm_cache_stats</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="n">local_uvm_cache_stats</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>  <span class="c1"># noqa C901</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">embedding_specs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
            <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">EmbeddingLocation</span><span class="p">,</span> <span class="n">ComputeDevice</span><span class="p">]</span>
        <span class="p">],</span>  <span class="c1"># tuple of (rows, dims, placements, compute_devices)</span>
        <span class="n">feature_table_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># [T]</span>
        <span class="n">cache_algorithm</span><span class="p">:</span> <span class="n">CacheAlgorithm</span> <span class="o">=</span> <span class="n">CacheAlgorithm</span><span class="o">.</span><span class="n">LRU</span><span class="p">,</span>
        <span class="n">cache_load_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">cache_sets</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">cache_reserved_memory</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">cache_precision</span><span class="p">:</span> <span class="n">SparseType</span> <span class="o">=</span> <span class="n">SparseType</span><span class="o">.</span><span class="n">FP32</span><span class="p">,</span>
        <span class="n">weights_precision</span><span class="p">:</span> <span class="n">SparseType</span> <span class="o">=</span> <span class="n">SparseType</span><span class="o">.</span><span class="n">FP32</span><span class="p">,</span>
        <span class="n">output_dtype</span><span class="p">:</span> <span class="n">SparseType</span> <span class="o">=</span> <span class="n">SparseType</span><span class="o">.</span><span class="n">FP32</span><span class="p">,</span>
        <span class="n">enforce_hbm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># place all weights/momentums in HBM when using cache</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">OptimType</span> <span class="o">=</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_SGD</span><span class="p">,</span>
        <span class="n">record_cache_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RecordCacheMetrics</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">gather_uvm_cache_stats</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="c1"># General Optimizer args</span>
        <span class="n">stochastic_rounding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">gradient_clipping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">max_gradient</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">max_norm</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="c1"># used by EXACT_ADAGRAD, EXACT_ROWWISE_ADAGRAD, EXACT_ROWWISE_WEIGHTED_ADAGRAD, LAMB, and ADAM only</span>
        <span class="c1"># NOTE that default is different from nn.optim.Adagrad default of 1e-10</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0e-8</span><span class="p">,</span>
        <span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>  <span class="c1"># used by LARS-SGD</span>
        <span class="c1"># EXACT_ADAGRAD, SGD, EXACT_SGD do not support weight decay</span>
        <span class="c1"># LAMB, ADAM, PARTIAL_ROWWISE_ADAM, PARTIAL_ROWWISE_LAMB, LARS_SGD support decoupled weight decay</span>
        <span class="c1"># EXACT_ROWWISE_WEIGHTED_ADAGRAD supports L2 weight decay</span>
        <span class="c1"># EXACT_ROWWISE_ADAGRAD support both L2 and decoupled weight decay (via weight_decay_mode)</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">weight_decay_mode</span><span class="p">:</span> <span class="n">WeightDecayMode</span> <span class="o">=</span> <span class="n">WeightDecayMode</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>  <span class="c1"># used by LARS-SGD,</span>
        <span class="n">beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>  <span class="c1"># used by LAMB and ADAM</span>
        <span class="n">beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span>  <span class="c1"># used by LAMB and ADAM</span>
        <span class="n">counter_based_regularization</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">CounterBasedRegularizationDefinition</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># used by Rowwise Adagrad</span>
        <span class="n">cowclip_regularization</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">CowClipDefinition</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># used by Rowwise Adagrad</span>
        <span class="n">pooling_mode</span><span class="p">:</span> <span class="n">PoolingMode</span> <span class="o">=</span> <span class="n">PoolingMode</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bounds_check_mode</span><span class="p">:</span> <span class="n">BoundsCheckMode</span> <span class="o">=</span> <span class="n">BoundsCheckMode</span><span class="o">.</span><span class="n">WARNING</span><span class="p">,</span>
        <span class="n">uvm_non_rowwise_momentum</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># place non-rowwise momentum on UVM</span>
        <span class="n">use_experimental_tbe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># set to True to use TBE v2 (only support NVIDIA GPUs)</span>
        <span class="c1"># set to True to enable prefetch pipeline, currently only supports LRU cache policy.</span>
        <span class="c1"># If a separate stream is used for prefetch, the optional forward_stream arg of prefetch function</span>
        <span class="c1"># should be set.</span>
        <span class="n">prefetch_pipeline</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">stats_reporter_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TBEStatsReporterConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SplitTableBatchedEmbeddingBagsCodegen</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pooling_mode</span> <span class="o">=</span> <span class="n">pooling_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bounds_check_mode_int</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">bounds_check_mode</span><span class="o">.</span><span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_precision</span> <span class="o">=</span> <span class="n">weights_precision</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dtype</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">output_dtype</span><span class="o">.</span><span class="n">as_int</span><span class="p">()</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">prefetch_pipeline</span> <span class="ow">or</span> <span class="n">cache_algorithm</span> <span class="o">==</span> <span class="n">CacheAlgorithm</span><span class="o">.</span><span class="n">LRU</span>
        <span class="p">),</span> <span class="s2">&quot;Only LRU cache policy supports prefetch_pipeline.&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_pipeline</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">prefetch_pipeline</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lock_cache_line</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_pipeline</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_uniq_cache_locations_bwd</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_pipeline</span>

        <span class="k">if</span> <span class="n">record_cache_metrics</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">record_cache_metrics</span> <span class="o">=</span> <span class="n">record_cache_metrics</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">record_cache_metrics</span> <span class="o">=</span> <span class="n">RecordCacheMetrics</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_specs</span> <span class="o">=</span> <span class="n">embedding_specs</span>
        <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">locations</span><span class="p">,</span> <span class="n">compute_devices</span><span class="p">)</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">embedding_specs</span><span class="p">)</span>
        <span class="n">T_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_specs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">dims</span>
        <span class="k">assert</span> <span class="n">T_</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="c1"># mixed D is not supported by no bag kernels</span>
        <span class="n">mixed_D</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">d</span> <span class="o">!=</span> <span class="n">D</span><span class="p">:</span>
                <span class="n">mixed_D</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">break</span>
        <span class="k">if</span> <span class="n">mixed_D</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pooling_mode</span> <span class="o">!=</span> <span class="n">PoolingMode</span><span class="o">.</span><span class="n">NONE</span>
            <span class="p">),</span> <span class="s2">&quot;Mixed dimension tables only supported for pooling tables.&quot;</span>

        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">cd</span> <span class="o">==</span> <span class="n">compute_devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">cd</span> <span class="ow">in</span> <span class="n">compute_devices</span>
        <span class="p">),</span> <span class="s2">&quot;Heterogenous compute_devices are NOT supported!&quot;</span>
        <span class="c1"># Split TBE has different function schemas for CUDA and CPU.</span>
        <span class="c1"># For MTIA device type, it uses the CPU one.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_cpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">compute_devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">ComputeDevice</span><span class="o">.</span><span class="n">CPU</span>
            <span class="ow">or</span> <span class="n">compute_devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">ComputeDevice</span><span class="o">.</span><span class="n">MTIA</span>
        <span class="p">)</span>

        <span class="k">assert</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cpu</span> <span class="ow">or</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">loc</span> <span class="o">==</span> <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">HOST</span> <span class="k">for</span> <span class="n">loc</span> <span class="ow">in</span> <span class="n">locations</span>
        <span class="p">),</span> <span class="s2">&quot;ComputeDevice.CPU is only for EmbeddingLocation.HOST!&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cpu</span> <span class="ow">or</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">loc</span> <span class="o">!=</span> <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">HOST</span> <span class="k">for</span> <span class="n">loc</span> <span class="ow">in</span> <span class="n">locations</span>
        <span class="p">),</span> <span class="s2">&quot;EmbeddingLocation.HOST doesn&#39;t work for CUDA device!&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cpu</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling_mode</span> <span class="o">==</span> <span class="n">PoolingMode</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">output_dtype</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="n">SparseType</span><span class="o">.</span><span class="n">FP32</span><span class="p">,</span>
                <span class="n">SparseType</span><span class="o">.</span><span class="n">FP16</span><span class="p">,</span>
                <span class="n">SparseType</span><span class="o">.</span><span class="n">BF16</span><span class="p">,</span>
            <span class="p">],</span> <span class="s2">&quot;Fused pooled embedding quantization only supported for cuda.&quot;</span>

        <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
                <span class="n">loc</span> <span class="o">==</span> <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">DEVICE</span> <span class="k">for</span> <span class="n">loc</span> <span class="ow">in</span> <span class="n">locations</span>
            <span class="p">),</span> <span class="s2">&quot;OptimType.NONE supports only EmbeddingLocation.DEVICE&quot;</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
                <span class="n">cd</span> <span class="o">==</span> <span class="n">ComputeDevice</span><span class="o">.</span><span class="n">CUDA</span> <span class="k">for</span> <span class="n">cd</span> <span class="ow">in</span> <span class="n">compute_devices</span>
            <span class="p">),</span> <span class="s2">&quot;OptimType.NONE supports only ComputeDevice.CUDA&quot;</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="n">mixed_D</span>
            <span class="p">),</span> <span class="s2">&quot;OptimType.NONE does not support mixed embedding dimension&quot;</span>

        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cpu</span>
                <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">())</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">current_device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">current_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># add placeholder require_grad param tensor to enable autograd with int8 weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">placeholder_autograd_tensor</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gather_uvm_cache_stats</span> <span class="o">=</span> <span class="n">gather_uvm_cache_stats</span>
        <span class="c1"># Define the size of uvm cache stats as class variable</span>
        <span class="c1"># to make it work with torch jit script.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">uvm_cache_stats_size</span> <span class="o">=</span> <span class="mi">6</span>
        <span class="c1"># 0: N_calls, 1: N_requested_indices, 2: N_unique_indices, 3: N_unique_misses,</span>
        <span class="c1"># 4: N_conflict_unique_misses, 5: N_conflict_misses</span>

        <span class="c1"># Reporter to collect runtime performance stats bottom-up. Reporter may</span>
        <span class="c1"># do aggregation across TBEs and publish results per training batch.</span>
        <span class="c1"># Example of stats include UVM cache hit rate, table I/O size, etc.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stats_reporter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TBEStatsReporter</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">stats_reporter_config</span><span class="o">.</span><span class="n">create_reporter</span><span class="p">()</span> <span class="k">if</span> <span class="n">stats_reporter_config</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">int8_emb_row_dim_offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">INT8_EMB_ROW_DIM_OFFSET</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">feature_table_map</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">feature_table_map</span> <span class="k">if</span> <span class="n">feature_table_map</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T_</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="n">T</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_table_map</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">T_</span> <span class="o">&lt;=</span> <span class="n">T</span>
        <span class="n">table_has_feature</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="n">T_</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_table_map</span><span class="p">:</span>
            <span class="n">table_has_feature</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">table_has_feature</span><span class="p">),</span> <span class="s2">&quot;Each table must have at least one feature!&quot;</span>

        <span class="n">feature_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">dims</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_table_map</span><span class="p">]</span>
        <span class="n">D_offsets</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">accumulate</span><span class="p">(</span><span class="n">feature_dims</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_D</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">D_offsets</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_D</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>
        <span class="n">cached_dims</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">embedding_spec</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">embedding_spec</span> <span class="ow">in</span> <span class="n">embedding_specs</span>
            <span class="k">if</span> <span class="n">embedding_spec</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">MANAGED_CACHING</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_D_cache</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">cached_dims</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cached_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;D_offsets&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">D_offsets</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">hash_size_cumsum</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">accumulate</span><span class="p">(</span><span class="n">rows</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_hash_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">hash_size_cumsum</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_hash_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_hash_size_bits</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_hash_size_bits</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">log2</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_hash_size</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># The last element is to easily access # of rows of each table by</span>
        <span class="c1"># hash_size_cumsum[t + 1] - hash_size_cumsum[t]</span>
        <span class="n">hash_size_cumsum</span> <span class="o">=</span> <span class="p">[</span><span class="n">hash_size_cumsum</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_table_map</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_hash_size</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;hash_size_cumsum&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">hash_size_cumsum</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
            <span class="p">),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;rows_per_table&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="p">[</span><span class="n">rows</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_table_map</span><span class="p">],</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;bounds_check_warning&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="c1"># Required for VBE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;feature_dims&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">feature_dims</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># A flag for indicating whether all embedding tables are placed in the</span>
        <span class="c1"># same locations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_homogeneous_placements</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">loc</span> <span class="o">==</span> <span class="n">locations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">loc</span> <span class="ow">in</span> <span class="n">locations</span>
        <span class="p">)</span>

        <span class="n">weight_split</span> <span class="o">=</span> <span class="n">construct_split_state</span><span class="p">(</span>
            <span class="n">embedding_specs</span><span class="p">,</span>
            <span class="n">rowwise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">cacheable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">precision</span><span class="o">=</span><span class="n">weights_precision</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">table_embedding_dtype</span> <span class="o">=</span> <span class="n">weights_precision</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_apply_split</span><span class="p">(</span>
            <span class="n">weight_split</span><span class="p">,</span>
            <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;weights&quot;</span><span class="p">,</span>
            <span class="c1"># pyre-fixme[6]: For 3rd param expected `Type[Type[_dtype]]` but got</span>
            <span class="c1">#  `Type[_dtype]`.</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">table_embedding_dtype</span><span class="p">,</span>
            <span class="n">enforce_hbm</span><span class="o">=</span><span class="n">enforce_hbm</span><span class="p">,</span>
            <span class="n">make_dev_param</span><span class="o">=</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span>
            <span class="n">dev_reshape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_D</span><span class="p">)</span> <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">assert</span> <span class="n">optimizer</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="n">OptimType</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span>
            <span class="n">OptimType</span><span class="o">.</span><span class="n">ROWWISE_ADAGRAD</span><span class="p">,</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Optimizer </span><span class="si">{</span><span class="n">optimizer</span><span class="si">}</span><span class="s2"> is deprecated in the CPU + GPU modes.&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cpu</span><span class="p">:</span>
            <span class="c1"># Construct optimizer states</span>
            <span class="k">assert</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ADAGRAD</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_ADAGRAD</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_WEIGHTED_ADAGRAD</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_SGD</span><span class="p">,</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Optimizer </span><span class="si">{</span><span class="n">optimizer</span><span class="si">}</span><span class="s2"> is not supported in CPU mode.&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">ADAM</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ADAGRAD</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_ADAGRAD</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_WEIGHTED_ADAGRAD</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_SGD</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">LAMB</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">LARS_SGD</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_ADAM</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_LAMB</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Optimizer </span><span class="si">{</span><span class="n">optimizer</span><span class="si">}</span><span class="s2"> is not supported.&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">stochastic_rounding</span> <span class="o">=</span> <span class="n">stochastic_rounding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay_mode</span> <span class="o">=</span> <span class="n">weight_decay_mode</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">weight_decay_mode</span> <span class="o">==</span> <span class="n">WeightDecayMode</span><span class="o">.</span><span class="n">COUNTER</span><span class="p">)</span> <span class="o">!=</span> <span class="p">(</span>
            <span class="n">counter_based_regularization</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                <span class="s2">&quot;Need to set weight_decay_mode=WeightDecayMode.COUNTER together with valid counter_based_regularization&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">weight_decay_mode</span> <span class="o">==</span> <span class="n">WeightDecayMode</span><span class="o">.</span><span class="n">COWCLIP</span><span class="p">)</span> <span class="o">!=</span> <span class="p">(</span>
            <span class="n">cowclip_regularization</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                <span class="s2">&quot;Need to set weight_decay_mode=WeightDecayMode.COWCLIP together with valid cowclip_regularization&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_used_rowwise_adagrad_with_counter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_ADAGRAD</span>
            <span class="ow">and</span> <span class="p">(</span>
                <span class="n">weight_decay_mode</span> <span class="ow">in</span> <span class="p">(</span><span class="n">WeightDecayMode</span><span class="o">.</span><span class="n">COUNTER</span><span class="p">,</span> <span class="n">WeightDecayMode</span><span class="o">.</span><span class="n">COWCLIP</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">counter_based_regularization</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">counter_based_regularization</span> <span class="o">=</span> <span class="n">CounterBasedRegularizationDefinition</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">cowclip_regularization</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cowclip_regularization</span> <span class="o">=</span> <span class="n">CowClipDefinition</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_max_counter_update_freq</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="c1"># Extract parameters from CounterBasedRegularizationDefinition or CowClipDefinition</span>
        <span class="c1"># which are passed as entries for OptimizerArgs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_used_rowwise_adagrad_with_counter</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay_mode</span> <span class="o">==</span> <span class="n">WeightDecayMode</span><span class="o">.</span><span class="n">COUNTER</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_max_counter_update_freq</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">counter_based_regularization</span><span class="o">.</span><span class="n">max_counter_update_freq</span>
                <span class="p">)</span>
                <span class="n">opt_arg_weight_decay_mode</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">counter_based_regularization</span><span class="o">.</span><span class="n">counter_weight_decay_mode</span>
                <span class="p">)</span>
                <span class="n">counter_halflife</span> <span class="o">=</span> <span class="n">counter_based_regularization</span><span class="o">.</span><span class="n">counter_halflife</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">opt_arg_weight_decay_mode</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">cowclip_regularization</span><span class="o">.</span><span class="n">counter_weight_decay_mode</span>
                <span class="p">)</span>
                <span class="n">counter_halflife</span> <span class="o">=</span> <span class="n">cowclip_regularization</span><span class="o">.</span><span class="n">counter_halflife</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">opt_arg_weight_decay_mode</span> <span class="o">=</span> <span class="n">weight_decay_mode</span>
            <span class="c1"># Default: -1, no decay applied, as a placeholder for OptimizerArgs</span>
            <span class="c1"># which should not be effective when CounterBasedRegularizationDefinition</span>
            <span class="c1"># and CowClipDefinition are not used</span>
            <span class="n">counter_halflife</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span> <span class="o">=</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_args</span><span class="o">.</span><span class="n">OptimizerArgs</span><span class="p">(</span>
            <span class="n">stochastic_rounding</span><span class="o">=</span><span class="n">stochastic_rounding</span><span class="p">,</span>
            <span class="n">gradient_clipping</span><span class="o">=</span><span class="n">gradient_clipping</span><span class="p">,</span>
            <span class="n">max_gradient</span><span class="o">=</span><span class="n">max_gradient</span><span class="p">,</span>
            <span class="n">max_norm</span><span class="o">=</span><span class="n">max_norm</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
            <span class="n">beta1</span><span class="o">=</span><span class="n">beta1</span><span class="p">,</span>
            <span class="n">beta2</span><span class="o">=</span><span class="n">beta2</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
            <span class="n">weight_decay_mode</span><span class="o">=</span><span class="n">opt_arg_weight_decay_mode</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
            <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">,</span>
            <span class="n">counter_halflife</span><span class="o">=</span><span class="n">counter_halflife</span><span class="p">,</span>
            <span class="n">adjustment_iter</span><span class="o">=</span><span class="n">counter_based_regularization</span><span class="o">.</span><span class="n">adjustment_iter</span><span class="p">,</span>
            <span class="n">adjustment_ub</span><span class="o">=</span><span class="n">counter_based_regularization</span><span class="o">.</span><span class="n">adjustment_ub</span><span class="p">,</span>
            <span class="n">learning_rate_mode</span><span class="o">=</span><span class="n">counter_based_regularization</span><span class="o">.</span><span class="n">learning_rate_mode</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="n">grad_sum_decay</span><span class="o">=</span><span class="n">counter_based_regularization</span><span class="o">.</span><span class="n">grad_sum_decay</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="n">tail_id_threshold</span><span class="o">=</span><span class="n">counter_based_regularization</span><span class="o">.</span><span class="n">tail_id_threshold</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>
            <span class="n">is_tail_id_thresh_ratio</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span>
                <span class="n">counter_based_regularization</span><span class="o">.</span><span class="n">tail_id_threshold</span><span class="o">.</span><span class="n">is_ratio</span>
            <span class="p">),</span>
            <span class="n">total_hash_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">total_hash_size</span><span class="p">,</span>
            <span class="n">weight_norm_coefficient</span><span class="o">=</span><span class="n">cowclip_regularization</span><span class="o">.</span><span class="n">weight_norm_coefficient</span><span class="p">,</span>
            <span class="n">lower_bound</span><span class="o">=</span><span class="n">cowclip_regularization</span><span class="o">.</span><span class="n">lower_bound</span><span class="p">,</span>
            <span class="n">regularization_mode</span><span class="o">=</span><span class="n">weight_decay_mode</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">optimizer</span> <span class="o">!=</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="p">(</span><span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_SGD</span><span class="p">,):</span>
                <span class="c1"># NOTE: make TorchScript work!</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_register_nonpersistent_buffers</span><span class="p">(</span><span class="s2">&quot;momentum1&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">rowwise</span> <span class="o">=</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="p">[</span>
                    <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_ADAGRAD</span><span class="p">,</span>
                    <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_WEIGHTED_ADAGRAD</span><span class="p">,</span>
                <span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_apply_split</span><span class="p">(</span>
                    <span class="n">construct_split_state</span><span class="p">(</span>
                        <span class="n">embedding_specs</span><span class="p">,</span>
                        <span class="n">rowwise</span><span class="o">=</span><span class="n">rowwise</span><span class="p">,</span>
                        <span class="n">cacheable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">placement</span><span class="o">=</span><span class="p">(</span>
                            <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">MANAGED</span>
                            <span class="k">if</span> <span class="p">((</span><span class="ow">not</span> <span class="n">rowwise</span><span class="p">)</span> <span class="ow">and</span> <span class="n">uvm_non_rowwise_momentum</span><span class="p">)</span>
                            <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">),</span>
                    <span class="p">),</span>
                    <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;momentum1&quot;</span><span class="p">,</span>
                    <span class="c1"># pyre-fixme[6]: Expected `Type[Type[torch._dtype]]` for 3rd param</span>
                    <span class="c1">#  but got `Type[torch.float32]`.</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                    <span class="n">enforce_hbm</span><span class="o">=</span><span class="n">enforce_hbm</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">ADAM</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_ADAM</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">LAMB</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_LAMB</span><span class="p">,</span>
            <span class="p">):</span>
                <span class="n">rowwise</span> <span class="o">=</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="p">(</span>
                    <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_ADAM</span><span class="p">,</span>
                    <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_LAMB</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_apply_split</span><span class="p">(</span>
                    <span class="n">construct_split_state</span><span class="p">(</span>
                        <span class="n">embedding_specs</span><span class="p">,</span>
                        <span class="n">rowwise</span><span class="o">=</span><span class="n">rowwise</span><span class="p">,</span>
                        <span class="n">cacheable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">placement</span><span class="o">=</span><span class="p">(</span>
                            <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">MANAGED</span>
                            <span class="k">if</span> <span class="p">((</span><span class="ow">not</span> <span class="n">rowwise</span><span class="p">)</span> <span class="ow">and</span> <span class="n">uvm_non_rowwise_momentum</span><span class="p">)</span>
                            <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">),</span>
                    <span class="p">),</span>
                    <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;momentum2&quot;</span><span class="p">,</span>
                    <span class="c1"># pyre-fixme[6]: Expected `Type[Type[torch._dtype]]` for 3rd param</span>
                    <span class="c1">#  but got `Type[torch.float32]`.</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># NOTE: make TorchScript work!</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_register_nonpersistent_buffers</span><span class="p">(</span><span class="s2">&quot;momentum2&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_used_rowwise_adagrad_with_counter</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_apply_split</span><span class="p">(</span>
                    <span class="n">construct_split_state</span><span class="p">(</span>
                        <span class="n">embedding_specs</span><span class="p">,</span>
                        <span class="n">rowwise</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">cacheable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;prev_iter&quot;</span><span class="p">,</span>
                    <span class="c1"># TODO: ideally we should use int64 to track iter but it failed to compile.</span>
                    <span class="c1"># It may be related to low precision training code. Currently using float32</span>
                    <span class="c1"># as a workaround while investigating the issue.</span>
                    <span class="c1"># pyre-fixme[6]: Expected `Type[Type[torch._dtype]]` for 3rd param</span>
                    <span class="c1">#  but got `Type[torch.float32]`.</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_apply_split</span><span class="p">(</span>
                    <span class="n">construct_split_state</span><span class="p">(</span>
                        <span class="n">embedding_specs</span><span class="p">,</span>
                        <span class="n">rowwise</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">cacheable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;row_counter&quot;</span><span class="p">,</span>
                    <span class="c1"># pyre-fixme[6]: Expected `Type[Type[torch._dtype]]` for 3rd param</span>
                    <span class="c1">#  but got `Type[torch.float32]`.</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                    <span class="s2">&quot;max_counter&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_register_nonpersistent_buffers</span><span class="p">(</span><span class="s2">&quot;prev_iter&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_register_nonpersistent_buffers</span><span class="p">(</span><span class="s2">&quot;row_counter&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                    <span class="s2">&quot;max_counter&quot;</span><span class="p">,</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                    <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">ADAM</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_WEIGHTED_ADAGRAD</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">LAMB</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_ADAM</span><span class="p">,</span>
                <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_LAMB</span><span class="p">,</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                    <span class="s2">&quot;iter&quot;</span><span class="p">,</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                    <span class="s2">&quot;iter&quot;</span><span class="p">,</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                    <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="n">cache_state</span> <span class="o">=</span> <span class="n">construct_cache_state</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">locations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_table_map</span><span class="p">)</span>

        <span class="c1"># Add table-wise cache miss counter</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">record_cache_metrics</span><span class="o">.</span><span class="n">record_tablewise_cache_miss</span><span class="p">:</span>
            <span class="n">num_tables</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cache_state</span><span class="o">.</span><span class="n">cache_hash_size_cumsum</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;table_wise_cache_miss&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="n">num_tables</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="c1"># NOTE: make TorchScript work!</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;table_wise_cache_miss&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="mi">0</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">cache_precision</span> <span class="o">==</span> <span class="n">SparseType</span><span class="o">.</span><span class="n">FP32</span><span class="p">:</span>
            <span class="n">cache_embedding_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
        <span class="k">elif</span> <span class="n">cache_precision</span> <span class="o">==</span> <span class="n">SparseType</span><span class="o">.</span><span class="n">FP16</span><span class="p">:</span>
            <span class="n">cache_embedding_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cache_precision </span><span class="si">{</span><span class="n">cache_precision</span><span class="si">}</span><span class="s2"> not supported!&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_apply_cache_state</span><span class="p">(</span>
            <span class="n">cache_state</span><span class="p">,</span>
            <span class="n">cache_algorithm</span><span class="p">,</span>
            <span class="n">cache_load_factor</span><span class="p">,</span>
            <span class="n">cache_sets</span><span class="p">,</span>
            <span class="n">cache_reserved_memory</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">cache_embedding_dtype</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Using fused </span><span class="si">{</span><span class="n">optimizer</span><span class="si">}</span><span class="s2"> with optimizer_args=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">optimizer</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="kc">None</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Using rowwise_adagrad_with_counter=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_used_rowwise_adagrad_with_counter</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Check whether to use TBE v2</span>
        <span class="n">is_experimental</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">fbgemm_exp_tbe</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;FBGEMM_EXPERIMENTAL_TBE&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">use_experimental_tbe</span><span class="p">:</span>
            <span class="n">is_experimental</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;use_experimental_tbe is set to True; Use experimental TBE: True&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">fbgemm_exp_tbe</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">is_experimental</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fbgemm_exp_tbe</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;FBGEMM_EXPERIMENTAL_TBE is set to </span><span class="si">{</span><span class="n">fbgemm_exp_tbe</span><span class="si">}</span><span class="s2">; &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Use experimental TBE: </span><span class="si">{</span><span class="n">is_experimental</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_experimental</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">is_experimental</span>

    <span class="k">def</span> <span class="nf">_register_nonpersistent_buffers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># NOTE: make TorchScript work!</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_dev&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
            <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_host&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
            <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_uvm&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
            <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_placements&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
            <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_offsets&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
            <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_physical_placements&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DoesNotHavePrefix</span><span class="p">()</span>
        <span class="n">dev_param</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_dev&quot;</span><span class="p">)</span>
        <span class="n">host_param</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_host&quot;</span><span class="p">)</span>
        <span class="n">uvm_param</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_uvm&quot;</span><span class="p">)</span>
        <span class="n">placements</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_physical_placements&quot;</span><span class="p">)</span>
        <span class="n">offsets</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_physical_offsets&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">dev_param</span><span class="p">,</span>
            <span class="n">host_param</span><span class="p">,</span>
            <span class="n">uvm_param</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">placements</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">offsets</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_all_states</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]:</span>
        <span class="n">all_states</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">prefix</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">,</span> <span class="s2">&quot;momentum1&quot;</span><span class="p">,</span> <span class="s2">&quot;momentum2&quot;</span><span class="p">,</span> <span class="s2">&quot;prev_iter&quot;</span><span class="p">,</span> <span class="s2">&quot;row_counter&quot;</span><span class="p">]:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">all_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_states</span><span class="p">(</span><span class="n">prefix</span><span class="p">))</span>
            <span class="k">except</span> <span class="n">DoesNotHavePrefix</span><span class="p">:</span>
                <span class="k">pass</span>
        <span class="k">return</span> <span class="n">all_states</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
    <span class="k">def</span> <span class="nf">get_cache_miss_counter</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># cache_miss_counter contains two items:</span>
        <span class="c1"># The first one is cache_miss_forward_count which records the total number of forwards which has at least one cache miss</span>
        <span class="c1"># The second one is the unique_cache_miss_count which records to total number of unique (dedup) cache misses</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_miss_counter</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
    <span class="k">def</span> <span class="nf">get_table_wise_cache_miss</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># table_wise_cache_miss contains all the cache miss count for each table in this embedding table object:</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">table_wise_cache_miss</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>  <span class="c1"># noqa: C901</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">offsets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">per_sample_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_requires_grad</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># 2D tensor of batch size for each rank and feature.</span>
        <span class="c1"># Shape (number of features, number of ranks)</span>
        <span class="n">batch_size_per_feature_per_rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">total_unique_indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">batch_size_per_feature_per_rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_ADAGRAD</span>
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_SGD</span>
            <span class="p">),</span> <span class="s2">&quot;Variable batch size TBE support is enabled for OptimType.EXACT_ROWWISE_ADAGRAD only&quot;</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pooling_mode</span> <span class="o">!=</span> <span class="n">PoolingMode</span><span class="o">.</span><span class="n">NONE</span><span class="o">.</span><span class="n">value</span>
            <span class="p">),</span> <span class="s2">&quot;Variable batch size TBE support is not enabled for PoolingMode.NONE&quot;</span>
            <span class="c1"># TODO: Add input check</span>
            <span class="n">zero_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

            <span class="c1"># Create B offsets</span>
            <span class="n">total_batch_size_per_feature</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">)</span> <span class="k">for</span> <span class="n">batch_sizes</span> <span class="ow">in</span> <span class="n">batch_size_per_feature_per_rank</span><span class="p">],</span>
                <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">max_B</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">total_batch_size_per_feature</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">Bs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">zero_tensor</span><span class="p">,</span> <span class="n">total_batch_size_per_feature</span><span class="p">])</span>
            <span class="n">B_offsets</span> <span class="o">=</span> <span class="n">Bs</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>

            <span class="c1"># Create output offsets</span>
            <span class="n">B_feature_rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">batch_size_per_feature_per_rank</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">max_B_feature_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">B_feature_rank</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="c1"># D-&gt;H only once</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feature_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_dims</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="n">output_sizes_feature_rank</span> <span class="o">=</span> <span class="n">B_feature_rank</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
                <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
            <span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_dims</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">output_offsets_feature_rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">zero_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                    <span class="n">output_sizes_feature_rank</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                <span class="p">]</span>
            <span class="p">)</span>
            <span class="n">output_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">output_offsets_feature_rank</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="c1"># TODO: Support INT8 output</span>
            <span class="c1"># B_offsets_rank_per_feature is for rank and (b, t) mapping</span>
            <span class="n">B_offsets_rank_per_feature</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">batch_size_per_feature</span>
                        <span class="k">for</span> <span class="n">batch_size_per_feature</span> <span class="ow">in</span> <span class="n">batch_size_per_feature_per_rank</span>
                    <span class="p">],</span>
                    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="n">B_offsets</span> <span class="o">=</span> <span class="n">B_offsets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">output_offsets_feature_rank</span> <span class="o">=</span> <span class="n">output_offsets_feature_rank</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">B_offsets_rank_per_feature</span> <span class="o">=</span> <span class="n">B_offsets_rank_per_feature</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

            <span class="c1"># TODO: Use int32 for B_offsets and int64 for output_offsets_feature_rank</span>
            <span class="n">vbe_metadata</span> <span class="o">=</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_args</span><span class="o">.</span><span class="n">VBEMetadata</span><span class="p">(</span>
                <span class="n">B_offsets</span><span class="o">=</span><span class="n">B_offsets</span><span class="p">,</span>
                <span class="n">output_offsets_feature_rank</span><span class="o">=</span><span class="n">output_offsets_feature_rank</span><span class="p">,</span>
                <span class="n">B_offsets_rank_per_feature</span><span class="o">=</span><span class="n">B_offsets_rank_per_feature</span><span class="p">,</span>
                <span class="n">max_B</span><span class="o">=</span><span class="n">max_B</span><span class="p">,</span>
                <span class="n">max_B_feature_rank</span><span class="o">=</span><span class="n">max_B_feature_rank</span><span class="p">,</span>
                <span class="n">output_size</span><span class="o">=</span><span class="n">output_size</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vbe_metadata</span> <span class="o">=</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_args</span><span class="o">.</span><span class="n">VBEMetadata</span><span class="p">(</span>
                <span class="n">B_offsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">output_offsets_feature_rank</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">B_offsets_rank_per_feature</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">max_B</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">max_B_feature_rank</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">output_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">offsets</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds_check_mode_int</span> <span class="o">!=</span> <span class="n">BoundsCheckMode</span><span class="o">.</span><span class="n">NONE</span><span class="o">.</span><span class="n">value</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">bounds_check_indices</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rows_per_table</span><span class="p">,</span>
                <span class="n">indices</span><span class="p">,</span>
                <span class="n">offsets</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bounds_check_mode_int</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bounds_check_warning</span><span class="p">,</span>
                <span class="n">per_sample_weights</span><span class="p">,</span>
                <span class="n">B_offsets</span><span class="o">=</span><span class="n">vbe_metadata</span><span class="o">.</span><span class="n">B_offsets</span><span class="p">,</span>
                <span class="n">max_B</span><span class="o">=</span><span class="n">vbe_metadata</span><span class="o">.</span><span class="n">max_B</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Storing indices and offsets for linear_cache_indices recomputation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="o">=</span> <span class="n">indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_offsets</span> <span class="o">=</span> <span class="n">offsets</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">timesteps_prefetched</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_prefetch</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">timesteps_prefetched</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">timesteps_prefetched</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_empty</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_list</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">common_args</span> <span class="o">=</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_args</span><span class="o">.</span><span class="n">CommonArgs</span><span class="p">(</span>
            <span class="n">placeholder_autograd_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">placeholder_autograd_tensor</span><span class="p">,</span>
            <span class="n">dev_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_dev</span><span class="p">,</span>
            <span class="n">host_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_host</span><span class="p">,</span>
            <span class="n">uvm_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_uvm</span><span class="p">,</span>
            <span class="n">lxu_cache_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_weights</span><span class="p">,</span>
            <span class="n">weights_placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_placements</span><span class="p">,</span>
            <span class="n">weights_offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_offsets</span><span class="p">,</span>
            <span class="n">D_offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">D_offsets</span><span class="p">,</span>
            <span class="n">total_D</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">total_D</span><span class="p">,</span>
            <span class="n">max_D</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_D</span><span class="p">,</span>
            <span class="n">hash_size_cumsum</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_size_cumsum</span><span class="p">,</span>
            <span class="n">total_hash_size_bits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">total_hash_size_bits</span><span class="p">,</span>
            <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
            <span class="n">offsets</span><span class="o">=</span><span class="n">offsets</span><span class="p">,</span>
            <span class="n">pooling_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pooling_mode</span><span class="p">,</span>
            <span class="n">indice_weights</span><span class="o">=</span><span class="n">per_sample_weights</span><span class="p">,</span>
            <span class="n">feature_requires_grad</span><span class="o">=</span><span class="n">feature_requires_grad</span><span class="p">,</span>
            <span class="n">lxu_cache_locations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations</span><span class="p">,</span>
            <span class="c1"># Pass the local_uvm_cache_stats bc only that information is</span>
            <span class="c1"># relevant for the current iteration</span>
            <span class="n">uvm_cache_stats</span><span class="o">=</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">local_uvm_cache_stats</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">gather_uvm_cache_stats</span>
                    <span class="c1"># Unique conflict misses are only collected when using CacheAlgorithm.LRU</span>
                    <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_algorithm</span> <span class="o">==</span> <span class="n">CacheAlgorithm</span><span class="o">.</span><span class="n">LRU</span>
                <span class="p">)</span>
                <span class="k">else</span> <span class="kc">None</span>
            <span class="p">),</span>
            <span class="n">output_dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dtype</span><span class="p">,</span>
            <span class="n">vbe_metadata</span><span class="o">=</span><span class="n">vbe_metadata</span><span class="p">,</span>
            <span class="n">is_experimental</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_experimental</span><span class="p">,</span>
            <span class="n">use_uniq_cache_locations_bwd</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_uniq_cache_locations_bwd</span><span class="p">,</span>
            <span class="n">use_homogeneous_placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_homogeneous_placements</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">total_unique_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="n">total_unique_indices</span> <span class="o">&lt;=</span> <span class="n">indices</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;OptimType.NONE requires total_unique_indices. Please pass it or check the value (total_unique_indices = </span><span class="si">{</span><span class="n">total_unique_indices</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="k">return</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_none</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
                <span class="n">common_args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="p">,</span> <span class="n">total_unique_indices</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_SGD</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_sgd</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">common_args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="p">)</span>

        <span class="n">momentum1</span> <span class="o">=</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_args</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span>
            <span class="n">dev</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1_dev</span><span class="p">,</span>
            <span class="n">host</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1_host</span><span class="p">,</span>
            <span class="n">uvm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1_uvm</span><span class="p">,</span>
            <span class="n">offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1_offsets</span><span class="p">,</span>
            <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1_placements</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">LARS_SGD</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_lars_sgd</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
                <span class="n">common_args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="p">,</span> <span class="n">momentum1</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ADAGRAD</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_adagrad</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
                <span class="n">common_args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="p">,</span> <span class="n">momentum1</span>
            <span class="p">)</span>

        <span class="n">momentum2</span> <span class="o">=</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_args</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span>
            <span class="n">dev</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum2_dev</span><span class="p">,</span>
            <span class="n">host</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum2_host</span><span class="p">,</span>
            <span class="n">uvm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum2_uvm</span><span class="p">,</span>
            <span class="n">offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum2_offsets</span><span class="p">,</span>
            <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum2_placements</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Ensure iter is always on CPU so the increment doesn&#39;t synchronize.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="o">.</span><span class="n">is_cpu</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_WEIGHTED_ADAGRAD</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_rowwise_weighted_adagrad</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
                <span class="n">common_args</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="p">,</span>
                <span class="n">momentum1</span><span class="p">,</span>
                <span class="c1"># pyre-fixme[6]: Expected `int` for 4th param but got `Union[float,</span>
                <span class="c1">#  int]`.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">ADAM</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_adam</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
                <span class="n">common_args</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="p">,</span>
                <span class="n">momentum1</span><span class="p">,</span>
                <span class="n">momentum2</span><span class="p">,</span>
                <span class="c1"># pyre-fixme[6]: Expected `int` for 5th param but got `Union[float,</span>
                <span class="c1">#  int]`.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_ADAM</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_partial_rowwise_adam</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
                <span class="n">common_args</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="p">,</span>
                <span class="n">momentum1</span><span class="p">,</span>
                <span class="n">momentum2</span><span class="p">,</span>
                <span class="c1"># pyre-fixme[6]: Expected `int` for 5th param but got `Union[float,</span>
                <span class="c1">#  int]`.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">LAMB</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_lamb</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
                <span class="n">common_args</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="p">,</span>
                <span class="n">momentum1</span><span class="p">,</span>
                <span class="n">momentum2</span><span class="p">,</span>
                <span class="c1"># pyre-fixme[6]: Expected `int` for 5th param but got `Union[float,</span>
                <span class="c1">#  int]`.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_LAMB</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_partial_rowwise_lamb</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
                <span class="n">common_args</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="p">,</span>
                <span class="n">momentum1</span><span class="p">,</span>
                <span class="n">momentum2</span><span class="p">,</span>
                <span class="c1"># pyre-fixme[6]: Expected `int` for 5th param but got `Union[float,</span>
                <span class="c1">#  int]`.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="p">)</span>

        <span class="n">prev_iter</span> <span class="o">=</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_args</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span>
            <span class="n">dev</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prev_iter_dev</span><span class="p">,</span>
            <span class="n">host</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prev_iter_host</span><span class="p">,</span>
            <span class="n">uvm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prev_iter_uvm</span><span class="p">,</span>
            <span class="n">offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prev_iter_offsets</span><span class="p">,</span>
            <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prev_iter_placements</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">row_counter</span> <span class="o">=</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_args</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span>
            <span class="n">dev</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_counter_dev</span><span class="p">,</span>
            <span class="n">host</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_counter_host</span><span class="p">,</span>
            <span class="n">uvm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_counter_uvm</span><span class="p">,</span>
            <span class="n">offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_counter_offsets</span><span class="p">,</span>
            <span class="n">placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_counter_placements</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_used_rowwise_adagrad_with_counter</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_max_counter_update_freq</span> <span class="o">&gt;</span> <span class="mi">0</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_counter_update_freq</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="p">):</span>
                <span class="n">row_counter_dev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_counter_dev</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">row_counter_dev</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">max_counter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">row_counter_dev</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">max_counter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_ADAGRAD</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_used_rowwise_adagrad_with_counter</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_rowwise_adagrad_with_counter</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
                    <span class="n">common_args</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="p">,</span>
                    <span class="n">momentum1</span><span class="p">,</span>
                    <span class="n">prev_iter</span><span class="p">,</span>
                    <span class="n">row_counter</span><span class="p">,</span>
                    <span class="c1"># pyre-fixme[6]: Expected `int` for 6th param but got `Union[float, int]`.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">max_counter</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">invokers</span><span class="o">.</span><span class="n">lookup_rowwise_adagrad</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
                    <span class="n">common_args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="p">,</span> <span class="n">momentum1</span>
                <span class="p">)</span>

        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid OptimType: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reset_uvm_cache_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gather_uvm_cache_stats</span>
        <span class="p">),</span> <span class="s2">&quot;gather_uvm_cache_stats should be set to true to access uvm cache stats.&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">uvm_cache_stats</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_uvm_cache_stats</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_uvm_cache_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_local_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gather_uvm_cache_stats</span>
        <span class="p">),</span> <span class="s2">&quot;gather_uvm_cache_stats should be set to true to access uvm cache stats.&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_uvm_cache_stats</span> <span class="k">if</span> <span class="n">use_local_cache</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">uvm_cache_stats</span>

    <span class="k">def</span> <span class="nf">print_uvm_cache_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_local_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">uvm_cache_stats</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_uvm_cache_stats</span><span class="p">(</span>
            <span class="n">use_local_cache</span>
        <span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;N_called: </span><span class="si">{</span><span class="n">uvm_cache_stats</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;N_requested_indices: </span><span class="si">{</span><span class="n">uvm_cache_stats</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;N_unique_indices: </span><span class="si">{</span><span class="n">uvm_cache_stats</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;N_unique_misses: </span><span class="si">{</span><span class="n">uvm_cache_stats</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;N_conflict_unique_misses: </span><span class="si">{</span><span class="n">uvm_cache_stats</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;N_conflict_misses: </span><span class="si">{</span><span class="n">uvm_cache_stats</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">uvm_cache_stats</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;unique indices / requested indices: </span><span class="si">{</span><span class="n">uvm_cache_stats</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="n">uvm_cache_stats</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;unique misses / requested indices: </span><span class="si">{</span><span class="n">uvm_cache_stats</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">/</span><span class="n">uvm_cache_stats</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">prefetch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">offsets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">forward_stream</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_stream</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">forward_stream</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_stream</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_stream</span> <span class="o">!=</span> <span class="n">forward_stream</span>
            <span class="p">),</span> <span class="s2">&quot;prefetch_stream and forward_stream should not be the same stream&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_prefetch</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">forward_stream</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_prefetch_tensors_record_stream</span><span class="p">(</span><span class="n">forward_stream</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_prefetch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">offsets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timestep</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timesteps_prefetched</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">timestep</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_weights</span><span class="o">.</span><span class="n">numel</span><span class="p">():</span>
            <span class="k">return</span>

        <span class="c1"># Clear the local_uvm_cache_stats before the prefetch instead of after</span>
        <span class="c1"># the prefetch step, since it will be used in the CommonArgs in the</span>
        <span class="c1"># forward step</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather_uvm_cache_stats</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">local_uvm_cache_stats</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

        <span class="n">linear_cache_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">linearize_cache_indices</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cache_hash_size_cumsum</span><span class="p">,</span>
            <span class="n">indices</span><span class="p">,</span>
            <span class="n">offsets</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">record_cache_metrics</span><span class="o">.</span><span class="n">record_cache_miss_counter</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">record_cache_metrics</span><span class="o">.</span><span class="n">record_tablewise_cache_miss</span>
        <span class="p">):</span>
            <span class="n">lxu_cache_locations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">lxu_cache_lookup</span><span class="p">(</span>
                <span class="n">linear_cache_indices</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_state</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">total_cache_hash_size</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">gather_uvm_cache_stats</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">local_uvm_cache_stats</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">record_cache_metrics</span><span class="o">.</span><span class="n">record_cache_miss_counter</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_update_cache_miss_counter</span><span class="p">(</span>
                    <span class="n">lxu_cache_locations</span><span class="p">,</span> <span class="n">linear_cache_indices</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">record_cache_metrics</span><span class="o">.</span><span class="n">record_tablewise_cache_miss</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_update_tablewise_cache_miss</span><span class="p">(</span>
                    <span class="n">lxu_cache_locations</span><span class="p">,</span> <span class="n">linear_cache_indices</span><span class="p">,</span> <span class="n">offsets</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_algorithm</span> <span class="o">==</span> <span class="n">CacheAlgorithm</span><span class="o">.</span><span class="n">LRU</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">lru_cache_populate</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights_uvm</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cache_hash_size_cumsum</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">total_cache_hash_size</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cache_index_table_map</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights_offsets</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">D_offsets</span><span class="p">,</span>
                <span class="n">linear_cache_indices</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_state</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_weights</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">timestep</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lxu_state</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stochastic_rounding</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">gather_uvm_cache_stats</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">local_uvm_cache_stats</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lock_cache_line</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locking_counter</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_algorithm</span> <span class="o">==</span> <span class="n">CacheAlgorithm</span><span class="o">.</span><span class="n">LFU</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">lfu_cache_populate</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights_uvm</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cache_hash_size_cumsum</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">total_cache_hash_size</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cache_index_table_map</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights_offsets</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">D_offsets</span><span class="p">,</span>
                <span class="n">linear_cache_indices</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_state</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_weights</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lxu_state</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stochastic_rounding</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_list</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_prefetch_depth</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;self.lxu_cache_locations_list has grown to size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_list</span><span class="p">)</span><span class="si">}</span><span class="s2">, this exceeds the maximum: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_prefetch_depth</span><span class="si">}</span><span class="s2">. This probably indicates an error in logic where prefetch() is being called more frequently than forward()&quot;</span>

        <span class="n">lxu_cache_locations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">lxu_cache_lookup</span><span class="p">(</span>
            <span class="n">linear_cache_indices</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_state</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_cache_hash_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gather_uvm_cache_stats</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">local_uvm_cache_stats</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lxu_cache_locations</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather_uvm_cache_stats</span><span class="p">:</span>
            <span class="c1"># Accumulate local_uvm_cache_stats (int32) into uvm_cache_stats (int64).</span>
            <span class="c1"># We may want to do this accumulation atomically, but as it&#39;s only</span>
            <span class="c1"># for monitoring, slightly inaccurate result may be acceptable.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">uvm_cache_stats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">uvm_cache_stats</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_uvm_cache_stats</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_prefetch_tensors_record_stream</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">forward_stream</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Record the tensors created by prefetch stream and consumed by forward/backward</span>
        <span class="c1"># to the forward stream. In PyTorch, each backward CUDA op runs on the same</span>
        <span class="c1"># stream that was used for its corresponding forward op.</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_list</span><span class="p">:</span>
            <span class="n">t</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span><span class="n">forward_stream</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_update_cache_miss_counter</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lxu_cache_locations</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">linear_cache_indices</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">CACHE_MISS</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">CACHE_HIT</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>

        <span class="n">cache_missed_locations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">lxu_cache_locations</span> <span class="o">==</span> <span class="n">CACHE_MISS</span><span class="p">,</span> <span class="n">linear_cache_indices</span><span class="p">,</span> <span class="n">CACHE_HIT</span>
        <span class="p">)</span>
        <span class="n">unique_ids_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">cache_missed_locations</span><span class="p">)</span>
        <span class="n">unique_ids_count_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">unique_ids_list</span> <span class="o">==</span> <span class="n">CACHE_HIT</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">miss_count</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">unique_ids_count_list</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cache_miss_counter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">miss_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cache_miss_counter</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">miss_count</span>

    <span class="k">def</span> <span class="nf">_update_tablewise_cache_miss</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lxu_cache_locations</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">linear_cache_indices</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">offsets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">CACHE_MISS</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">CACHE_HIT</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>

        <span class="n">num_tables</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_hash_size_cumsum</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">num_offsets_per_table</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">offsets</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">num_tables</span>
        <span class="n">cache_missed_locations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">lxu_cache_locations</span> <span class="o">==</span> <span class="n">CACHE_MISS</span><span class="p">,</span> <span class="n">linear_cache_indices</span><span class="p">,</span> <span class="n">CACHE_HIT</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tables</span><span class="p">):</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">num_offsets_per_table</span><span class="p">]</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_offsets_per_table</span><span class="p">]</span>

            <span class="n">current_cache_missed_locations</span> <span class="o">=</span> <span class="n">cache_missed_locations</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
            <span class="n">unique_ids_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">current_cache_missed_locations</span><span class="p">)</span>
            <span class="n">unique_ids_count_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">unique_ids_list</span> <span class="o">==</span> <span class="n">CACHE_HIT</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">miss_count</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">unique_ids_count_list</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">table_wise_cache_miss</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">miss_count</span>

    <span class="k">def</span> <span class="nf">init_embedding_weights_uniform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">min_val</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">max_val</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_embedding_weights</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_precision</span> <span class="o">==</span> <span class="n">SparseType</span><span class="o">.</span><span class="n">INT8</span><span class="p">:</span>
            <span class="c1"># TODO: add in-place FloatToFused8BitRowwiseQuantized conversion</span>
            <span class="k">for</span> <span class="n">emb</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">:</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">emb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
                <span class="p">),</span> <span class="s2">&quot;Int8 embedding only supported for 2D weight tensors.&quot;</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">int8_emb_row_dim_offset</span><span class="p">]</span>
                <span class="n">tmp_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">)</span>
                <span class="n">tmp_emb</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">)</span>
                <span class="n">tmp_emb_i8</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">FloatToFused8BitRowwiseQuantized</span><span class="p">(</span><span class="n">tmp_emb</span><span class="p">)</span>
                <span class="n">emb</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">tmp_emb_i8</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">:</span>
                <span class="n">param</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">ignore</span>
    <span class="k">def</span> <span class="nf">split_embedding_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a list of weights, split by table</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_specs</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_precision</span> <span class="o">==</span> <span class="n">SparseType</span><span class="o">.</span><span class="n">INT8</span><span class="p">:</span>
                <span class="n">dim</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">int8_emb_row_dim_offset</span>
            <span class="n">placement</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_physical_placements</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_physical_offsets</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">placement</span> <span class="o">==</span> <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">DEVICE</span><span class="o">.</span><span class="n">value</span><span class="p">:</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_dev</span>
            <span class="k">elif</span> <span class="n">placement</span> <span class="o">==</span> <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">HOST</span><span class="o">.</span><span class="n">value</span><span class="p">:</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_host</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_uvm</span>
            <span class="k">if</span> <span class="n">weights</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">weights</span><span class="o">.</span><span class="n">detach</span><span class="p">()[</span><span class="n">offset</span> <span class="p">:</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">dim</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">splits</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">ignore</span>
    <span class="k">def</span> <span class="nf">get_optimizer_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Getting optimizer buffer is not supported for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buffer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="n">state</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">buffer</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
    <span class="k">def</span> <span class="nf">get_optimizer_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the optimizer state dict that matches the OSS Pytorch optims</span>
<span class="sd">        TODO: populate the supported list of optimizers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">split_optimizer_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_optimizer_states</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_ADAGRAD</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_WEIGHTED_ADAGRAD</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ADAGRAD</span>
        <span class="p">):</span>
            <span class="n">list_of_state_dict</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">(</span>
                    <span class="p">{</span><span class="s2">&quot;sum&quot;</span><span class="p">:</span> <span class="n">states</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;prev_iter&quot;</span><span class="p">:</span> <span class="n">states</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;row_counter&quot;</span><span class="p">:</span> <span class="n">states</span><span class="p">[</span><span class="mi">2</span><span class="p">]}</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_used_rowwise_adagrad_with_counter</span>
                    <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;sum&quot;</span><span class="p">:</span> <span class="n">states</span><span class="p">[</span><span class="mi">0</span><span class="p">]}</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">states</span> <span class="ow">in</span> <span class="n">split_optimizer_states</span>
            <span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">SGD</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_SGD</span><span class="p">:</span>
            <span class="n">list_of_state_dict</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;momentum_buffer&quot;</span><span class="p">:</span> <span class="n">states</span><span class="p">[</span><span class="mi">0</span><span class="p">]}</span> <span class="k">for</span> <span class="n">states</span> <span class="ow">in</span> <span class="n">split_optimizer_states</span>
            <span class="p">]</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">ADAM</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_ADAM</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">LAMB</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_LAMB</span>
        <span class="p">):</span>
            <span class="n">list_of_state_dict</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;exp_avg&quot;</span><span class="p">:</span> <span class="n">states</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;exp_avg_sq&quot;</span><span class="p">:</span> <span class="n">states</span><span class="p">[</span><span class="mi">1</span><span class="p">]}</span>
                <span class="k">for</span> <span class="n">states</span> <span class="ow">in</span> <span class="n">split_optimizer_states</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Getting optimizer state </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="si">}</span><span class="s2"> is not implmeneted&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">list_of_state_dict</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">ignore</span>
    <span class="k">def</span> <span class="nf">split_optimizer_states</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a list of states, split by table</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Getting optimizer states is not supported for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">def</span> <span class="nf">get_optimizer_states</span><span class="p">(</span>
            <span class="n">state_dev</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
            <span class="n">state_host</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
            <span class="n">state_uvm</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
            <span class="n">state_offsets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
            <span class="n">state_placements</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
            <span class="n">rowwise</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
            <span class="n">splits</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_specs</span><span class="p">):</span>
                <span class="n">offset</span> <span class="o">=</span> <span class="n">state_offsets</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
                <span class="n">placement</span> <span class="o">=</span> <span class="n">state_placements</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">placement</span> <span class="o">==</span> <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">state_dev</span>
                <span class="k">elif</span> <span class="n">placement</span> <span class="o">==</span> <span class="n">EmbeddingLocation</span><span class="o">.</span><span class="n">HOST</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">state_host</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">state_uvm</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">rowwise</span><span class="p">:</span>
                    <span class="n">splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">state</span><span class="o">.</span><span class="n">detach</span><span class="p">()[</span><span class="n">offset</span> <span class="p">:</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">dim</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">detach</span><span class="p">()[</span><span class="n">offset</span> <span class="p">:</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">rows</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">rows</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">splits</span>

        <span class="n">states</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_SGD</span><span class="p">,):</span>
            <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">get_optimizer_states</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">momentum1_dev</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">momentum1_host</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">momentum1_uvm</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">momentum1_physical_offsets</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">momentum1_physical_placements</span><span class="p">,</span>
                    <span class="n">rowwise</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span>
                    <span class="ow">in</span> <span class="p">[</span>
                        <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_ADAGRAD</span><span class="p">,</span>
                        <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_WEIGHTED_ADAGRAD</span><span class="p">,</span>
                    <span class="p">],</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="n">OptimType</span><span class="o">.</span><span class="n">ADAM</span><span class="p">,</span>
            <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_ADAM</span><span class="p">,</span>
            <span class="n">OptimType</span><span class="o">.</span><span class="n">LAMB</span><span class="p">,</span>
            <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_LAMB</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">get_optimizer_states</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">momentum2_dev</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">momentum2_host</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">momentum2_uvm</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">momentum2_physical_offsets</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">momentum2_physical_placements</span><span class="p">,</span>
                    <span class="n">rowwise</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span>
                    <span class="ow">in</span> <span class="p">(</span><span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_ADAM</span><span class="p">,</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">PARTIAL_ROWWISE_LAMB</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_used_rowwise_adagrad_with_counter</span><span class="p">:</span>
            <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">get_optimizer_states</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">prev_iter_dev</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">prev_iter_host</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">prev_iter_uvm</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">prev_iter_physical_offsets</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">prev_iter_physical_placements</span><span class="p">,</span>
                    <span class="n">rowwise</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">get_optimizer_states</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">row_counter_dev</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">row_counter_host</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">row_counter_uvm</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">row_counter_physical_offsets</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">row_counter_physical_placements</span><span class="p">,</span>
                    <span class="n">rowwise</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">return_states</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">states</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">return_states</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
    <span class="k">def</span> <span class="nf">set_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the learning rate.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Setting learning rate is not supported for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_learning_rate</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">ignore</span>
    <span class="k">def</span> <span class="nf">_set_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Helper function to script `set_learning_rate`.</span>
<span class="sd">        Note that returning None does not work.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_args</span><span class="o">.</span><span class="n">_replace</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
        <span class="k">return</span> <span class="mf">0.0</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
    <span class="k">def</span> <span class="nf">set_optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the optimizer step.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Setting optimizer step is not supported for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">step</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
    <span class="k">def</span> <span class="nf">flush</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_weights</span><span class="o">.</span><span class="n">numel</span><span class="p">():</span>
            <span class="k">return</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">lxu_cache_flush</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights_uvm</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cache_hash_size_cumsum</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cache_index_table_map</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights_offsets</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">D_offsets</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_D</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_state</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_weights</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stochastic_rounding</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_apply_split</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">split</span><span class="p">:</span> <span class="n">SplitState</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">],</span>
        <span class="n">enforce_hbm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">make_dev_param</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">dev_reshape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">apply_split_helper</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">,</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="nb">setattr</span><span class="p">,</span> <span class="bp">self</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_cpu</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feature_table_map</span><span class="p">,</span>
            <span class="n">split</span><span class="p">,</span>
            <span class="n">prefix</span><span class="p">,</span>
            <span class="n">dtype</span><span class="p">,</span>
            <span class="n">enforce_hbm</span><span class="p">,</span>
            <span class="n">make_dev_param</span><span class="p">,</span>
            <span class="n">dev_reshape</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_apply_cache_state</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cache_state</span><span class="p">:</span> <span class="n">CacheState</span><span class="p">,</span>
        <span class="n">cache_algorithm</span><span class="p">:</span> <span class="n">CacheAlgorithm</span><span class="p">,</span>
        <span class="n">cache_load_factor</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">cache_sets</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">cache_reserved_memory</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache_algorithm</span> <span class="o">=</span> <span class="n">cache_algorithm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timestep</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timesteps_prefetched</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_prefetch_depth</span> <span class="o">=</span> <span class="n">MAX_PREFETCH_DEPTH</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_empty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
            <span class="mi">0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span>
        <span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_empty</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_empty</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_offsets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations_empty</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_stream</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_init_uvm_cache_stats</span><span class="p">()</span>

        <span class="c1"># NOTE: no cache for CPU mode!</span>
        <span class="k">if</span> <span class="n">cache_state</span><span class="o">.</span><span class="n">total_cache_hash_size</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cpu</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;lxu_cache_weights&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="c1"># NOTE: make TorchScript work!</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;cache_hash_size_cumsum&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;total_cache_hash_size&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;cache_index_table_map&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;lxu_cache_state&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;lxu_state&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;cache_miss_counter&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_uvm_cache_counter</span><span class="p">(</span><span class="n">cache_sets</span><span class="p">,</span> <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="k">assert</span> <span class="n">cache_load_factor</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="n">element_size</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span> <span class="k">else</span> <span class="mi">4</span>
        <span class="k">if</span> <span class="n">cache_sets</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">total_memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">current_device</span>
            <span class="p">)</span><span class="o">.</span><span class="n">total_memory</span>
            <span class="n">free_memory</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">total_memory</span>
                <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_reserved</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">)</span>
                <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="n">cache_reserved_memory</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="n">free_memory</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="n">cache_sets</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nb">int</span><span class="p">(</span><span class="n">cache_state</span><span class="o">.</span><span class="n">total_cache_hash_size</span> <span class="o">*</span> <span class="n">cache_load_factor</span><span class="p">)</span>
                <span class="o">+</span> <span class="n">DEFAULT_ASSOC</span>
                <span class="o">-</span> <span class="mi">1</span>
            <span class="p">)</span> <span class="o">//</span> <span class="n">DEFAULT_ASSOC</span>
            <span class="n">cache_sets</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">cache_sets</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">cache_sets</span>
            <span class="n">cache_size</span> <span class="o">=</span> <span class="n">cache_sets</span> <span class="o">*</span> <span class="n">DEFAULT_ASSOC</span> <span class="o">*</span> <span class="n">element_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_D_cache</span>
            <span class="k">if</span> <span class="n">cache_size</span> <span class="o">&gt;</span> <span class="n">free_memory</span><span class="p">:</span>
                <span class="n">cache_sets</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="nb">int</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">free_memory</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_D_cache</span> <span class="o">/</span> <span class="n">element_size</span><span class="p">)</span>
                    <span class="o">+</span> <span class="n">DEFAULT_ASSOC</span>
                    <span class="o">-</span> <span class="mi">1</span>
                <span class="p">)</span> <span class="o">//</span> <span class="n">DEFAULT_ASSOC</span>
        <span class="n">cache_load_factor</span> <span class="o">=</span> <span class="p">(</span>
            <span class="mf">1.0</span> <span class="o">*</span> <span class="n">cache_sets</span> <span class="o">*</span> <span class="n">DEFAULT_ASSOC</span> <span class="o">/</span> <span class="nb">int</span><span class="p">(</span><span class="n">cache_state</span><span class="o">.</span><span class="n">total_cache_hash_size</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="n">cache_sets</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">cache_algorithm</span> <span class="o">==</span> <span class="n">CacheAlgorithm</span><span class="o">.</span><span class="n">LFU</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">cache_sets</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="o">**</span><span class="mi">24</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">cache_size</span> <span class="o">=</span> <span class="n">cache_sets</span> <span class="o">*</span> <span class="n">DEFAULT_ASSOC</span> <span class="o">*</span> <span class="n">element_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_D_cache</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Using on-device cache with admission algorithm &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cache_algorithm</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">cache_sets</span><span class="si">}</span><span class="s2"> sets, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;load_factor: </span><span class="si">{</span><span class="n">cache_load_factor</span><span class="w"> </span><span class="si">:</span><span class="s2"> .3f</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;cache_size: </span><span class="si">{</span><span class="n">cache_size</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1024.0</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1024.0</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1024.0</span><span class="w"> </span><span class="si">:</span><span class="s2"> .2f</span><span class="si">}</span><span class="s2">GB, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;cache_precision: </span><span class="si">{</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">total_cache_hash_size</span> <span class="o">=</span> <span class="n">cache_state</span><span class="o">.</span><span class="n">total_cache_hash_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;cache_hash_size_cumsum&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">cache_state</span><span class="o">.</span><span class="n">cache_hash_size_cumsum</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;cache_index_table_map&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">cache_state</span><span class="o">.</span><span class="n">cache_index_table_map</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;lxu_cache_state&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">cache_sets</span><span class="p">,</span> <span class="n">DEFAULT_ASSOC</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
            <span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;lxu_cache_weights&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">cache_sets</span> <span class="o">*</span> <span class="n">DEFAULT_ASSOC</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">max_D_cache</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;lxu_state&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">size</span><span class="o">=</span><span class="p">(</span>
                    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_cache_hash_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,)</span>
                    <span class="k">if</span> <span class="n">cache_algorithm</span> <span class="o">==</span> <span class="n">CacheAlgorithm</span><span class="o">.</span><span class="n">LFU</span>
                    <span class="k">else</span> <span class="p">(</span><span class="n">cache_sets</span><span class="p">,</span> <span class="n">DEFAULT_ASSOC</span><span class="p">)</span>
                <span class="p">),</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;cache_miss_counter&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_uvm_cache_counter</span><span class="p">(</span><span class="n">cache_sets</span><span class="p">,</span> <span class="n">persistent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_pipeline</span><span class="p">:</span>
            <span class="c1"># using the placeholder_autograd_tensor to make sure</span>
            <span class="c1"># the hook is executed after the backward pass</span>
            <span class="c1"># not using register_module_full_backward_hook</span>
            <span class="c1"># due to https://github.com/pytorch/pytorch/issues/100528</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">placeholder_autograd_tensor</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sync_stream_post_backward</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_full_backward_pre_hook</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_update_cache_counter_and_locations</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">cache_algorithm</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">CacheAlgorithm</span><span class="o">.</span><span class="n">LFU</span><span class="p">,</span> <span class="n">CacheAlgorithm</span><span class="o">.</span><span class="n">LRU</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;cache_algorithm must be </span><span class="si">{</span><span class="n">CacheAlgorithm</span><span class="o">.</span><span class="n">LRU</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;or </span><span class="si">{</span><span class="n">CacheAlgorithm</span><span class="o">.</span><span class="n">LFU</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sync_stream_post_backward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">grad</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        backward hook function when prefetch_pipeline is enabled.</span>

<span class="sd">        With the pipeline, prefetch(batch_{i+2}) may overlap with backward(batch_{i}).</span>
<span class="sd">        There is race condition that backward(batch_i) writes to UVM memory and</span>
<span class="sd">        at the same time prefetch(batch_{i+2}) loads UVM memory to cache. This stream sync forces</span>
<span class="sd">        backward(batch_i) to finish before prefetch(batch_{i+2}).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_stream</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_stream</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">_update_cache_counter_and_locations</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">grad_input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Backward prehook function when prefetch_pipeline is enabled.</span>

<span class="sd">        This function does 3 things:</span>
<span class="sd">        1. backward stream waits for prefetch stream to finish.</span>
<span class="sd">        Otherwise the prefetch(batch_{i+1}) might overlap with backward(batch_i).</span>
<span class="sd">        If an idx is not in cache in batch_i, but it is being inserted in batch_{i+1},</span>
<span class="sd">        there is race condition that backward(batch_i) writes to UVM memory and</span>
<span class="sd">        at the same time prefetch(batch_{i+1}) loads UVM memory to cache.</span>

<span class="sd">        2. decrement the lxu_cache_locking_counter to indicate the current batch is finished.</span>
<span class="sd">        The lxu_cache_locking_counter is updated in both prefetch and TBE backward.</span>
<span class="sd">        As there is no overlap between prefetch and backward, we can decrement either before or</span>
<span class="sd">        after backward. It&#39;s better to decrement before lxu_cache_locations gets updated.</span>

<span class="sd">        3. update lxu_cache_locations to address the cache inconsistency issue.</span>
<span class="sd">        In the case that the same index is not inserted into cache in batch_i,</span>
<span class="sd">        but it is inserted in batch_{i+1}, the cache can be invalid in</span>
<span class="sd">        the sense that the cached weight for this index does not have the</span>
<span class="sd">        backward update of batch_i.</span>

<span class="sd">        Example of the issue is as follows:</span>
<span class="sd">        idx is in batch_i, batch_{i+1}</span>
<span class="sd">        prefetch(batch_i)</span>
<span class="sd">          - failed to insert idx into cache, cache_locations_batch_i of idx is -1 (cache miss)</span>
<span class="sd">        forward(batch_i)</span>
<span class="sd">        prefetch(batch_{i+1})</span>
<span class="sd">          - insert idx into cache, cache is loaded from host memory</span>
<span class="sd">        backward(batch_i)</span>
<span class="sd">          - cache_locations_batch_i of idx is -1, the host memory is updated</span>
<span class="sd">        forward(batch_{i+1})</span>
<span class="sd">          - OUTPUT IS WRONG. the weight for idx is fetched from cache, but the cache is outdated.</span>

<span class="sd">        The fix to this cache inconsistency is to update the cache_locations_batch_i before backward of batch_i,</span>
<span class="sd">        so that the cache gets updated correctly by the backward pass of TBE.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_stream</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># need to wait for the prefetch of next batch,</span>
            <span class="c1"># so that cache states are valid</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prefetch_stream</span><span class="p">)</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">lxu_cache_locking_counter_decrement</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locking_counter</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Recompute linear_cache_indices</span>
        <span class="n">linear_cache_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">linearize_cache_indices</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cache_hash_size_cumsum</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_offsets</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="p">(</span>
            <span class="n">linear_unique_indices</span><span class="p">,</span>
            <span class="n">linear_unique_indices_length</span><span class="p">,</span>
            <span class="n">_</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">get_unique_indices</span><span class="p">(</span>
            <span class="n">linear_cache_indices</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_cache_hash_size</span><span class="p">,</span>
            <span class="n">compute_count</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">lxu_cache_lookup</span><span class="p">(</span>
            <span class="n">linear_unique_indices</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_state</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_cache_hash_size</span><span class="p">,</span>
            <span class="n">gather_cache_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># not collecting cache stats</span>
            <span class="n">num_uniq_cache_indices</span><span class="o">=</span><span class="n">linear_unique_indices_length</span><span class="p">,</span>
            <span class="n">lxu_cache_locations_output</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_locations</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_init_uvm_cache_counter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cache_sets</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">persistent</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prefetch_pipeline</span> <span class="ow">and</span> <span class="n">persistent</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;lxu_cache_locking_counter&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="n">cache_sets</span><span class="p">,</span>
                    <span class="n">DEFAULT_ASSOC</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;lxu_cache_locking_counter&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                <span class="n">persistent</span><span class="o">=</span><span class="n">persistent</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_init_uvm_cache_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather_uvm_cache_stats</span><span class="p">:</span>
            <span class="c1"># If uvm_cache_stats is not enabled, register stub entries via buffer to state_dict for TorchScript to JIT properly.</span>
            <span class="c1"># Since we&#39;re not using these variables, we can choose minimize tensor size to keep state_dict size small.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;uvm_cache_stats&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="mi">1</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;local_uvm_cache_stats&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="mi">1</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;uvm_cache_stats&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uvm_cache_stats_size</span><span class="p">,),</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;local_uvm_cache_stats&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uvm_cache_stats_size</span><span class="p">,),</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset_uvm_cache_stats</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reset_cache_states</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_weights</span><span class="o">.</span><span class="n">numel</span><span class="p">():</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_state</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lxu_state</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timestep</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">reset_embedding_weight_momentum</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pruned_indices</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">pruned_indices_offsets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">logical_table_ids</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">buffer_ids</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="n">OptimType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Resetting embedding weight momentum is not supported for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">total_cache_hash_size</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_cache_hash_size</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
            <span class="n">total_cache_hash_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_cache_hash_size</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">total_cache_hash_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_cache_hash_size</span>

        <span class="n">rowwise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_ADAGRAD</span><span class="p">,</span>
            <span class="n">OptimType</span><span class="o">.</span><span class="n">EXACT_ROWWISE_WEIGHTED_ADAGRAD</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="n">rowwise</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">reset_weight_momentum</span><span class="p">(</span>
                <span class="n">dev_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_dev</span><span class="p">,</span>
                <span class="n">uvm_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_uvm</span><span class="p">,</span>
                <span class="n">lxu_cache_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_weights</span><span class="p">,</span>
                <span class="n">weights_placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_placements</span><span class="p">,</span>
                <span class="n">weights_offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_offsets</span><span class="p">,</span>
                <span class="n">momentum1_dev</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1_dev</span><span class="p">,</span>
                <span class="n">momentum1_uvm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1_uvm</span><span class="p">,</span>
                <span class="n">momentum1_placements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1_placements</span><span class="p">,</span>
                <span class="n">momentum1_offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum1_offsets</span><span class="p">,</span>
                <span class="n">D_offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">D_offsets</span><span class="p">,</span>
                <span class="n">pruned_indices</span><span class="o">=</span><span class="n">pruned_indices</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                <span class="n">pruned_indices_offsets</span><span class="o">=</span><span class="n">pruned_indices_offsets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span>
                <span class="p">),</span>
                <span class="n">logical_table_ids</span><span class="o">=</span><span class="n">logical_table_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                <span class="n">buffer_ids</span><span class="o">=</span><span class="n">buffer_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">),</span>
                <span class="n">cache_hash_size_cumsum</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_hash_size_cumsum</span><span class="p">,</span>
                <span class="n">lxu_cache_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lxu_cache_state</span><span class="p">,</span>
                <span class="n">total_cache_hash_size</span><span class="o">=</span><span class="n">total_cache_hash_size</span><span class="p">,</span>
            <span class="p">)</span></div>


<span class="k">class</span> <span class="nc">DenseTableBatchedEmbeddingBagsCodegen</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Table-batched version of nn.EmbeddingBag(sparse=False)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">weights</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">weights_offsets</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">D_offsets</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">total_D</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">max_D</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">hash_size_cumsum</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">total_hash_size_bits</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">embedding_specs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">embedding_specs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>  <span class="c1"># tuple of (rows, dims)</span>
        <span class="n">feature_table_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># [T]</span>
        <span class="n">weights_precision</span><span class="p">:</span> <span class="n">SparseType</span> <span class="o">=</span> <span class="n">SparseType</span><span class="o">.</span><span class="n">FP32</span><span class="p">,</span>
        <span class="n">pooling_mode</span><span class="p">:</span> <span class="n">PoolingMode</span> <span class="o">=</span> <span class="n">PoolingMode</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span>
        <span class="n">use_cpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">output_dtype</span><span class="p">:</span> <span class="n">SparseType</span> <span class="o">=</span> <span class="n">SparseType</span><span class="o">.</span><span class="n">FP32</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># noqa C901  # tuple of (rows, dims,)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DenseTableBatchedEmbeddingBagsCodegen</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pooling_mode</span> <span class="o">=</span> <span class="n">pooling_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_precision</span> <span class="o">=</span> <span class="n">weights_precision</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dtype</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">output_dtype</span><span class="o">.</span><span class="n">as_int</span><span class="p">()</span>
        <span class="n">table_embedding_dtype</span> <span class="o">=</span> <span class="n">weights_precision</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">use_cpu</span> <span class="o">=</span> <span class="n">use_cpu</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cpu</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling_mode</span> <span class="o">==</span> <span class="n">PoolingMode</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">output_dtype</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="n">SparseType</span><span class="o">.</span><span class="n">FP32</span><span class="p">,</span>
                <span class="n">SparseType</span><span class="o">.</span><span class="n">FP16</span><span class="p">,</span>
                <span class="n">SparseType</span><span class="o">.</span><span class="n">BF16</span><span class="p">,</span>
            <span class="p">],</span> <span class="s2">&quot;Fused pooled embedding quantization only supported for cuda.&quot;</span>

        <span class="c1"># pyre-fixme[8]: Attribute has type `device`; used as `Union[int, device]`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cpu</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_specs</span> <span class="o">=</span> <span class="n">embedding_specs</span>
        <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">embedding_specs</span><span class="p">)</span>
        <span class="n">T_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_specs</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">T_</span> <span class="o">&gt;</span> <span class="mi">0</span>

        <span class="n">feature_table_map</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">feature_table_map</span> <span class="k">if</span> <span class="n">feature_table_map</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T_</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="n">T</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_table_map</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">T_</span> <span class="o">&lt;=</span> <span class="n">T</span>
        <span class="n">D_offsets</span> <span class="o">=</span> <span class="p">[</span><span class="n">dims</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">feature_table_map</span><span class="p">]</span>
        <span class="n">D_offsets</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">accumulate</span><span class="p">(</span><span class="n">D_offsets</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_D</span> <span class="o">=</span> <span class="n">D_offsets</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_D</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;D_offsets&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">D_offsets</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">D_offsets</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="n">T</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">hash_size_cumsum</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">accumulate</span><span class="p">(</span><span class="n">rows</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">hash_size_cumsum</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_hash_size_bits</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_hash_size_bits</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">log2</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">hash_size_cumsum</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># The last element is to easily access # of rows of each table by</span>
        <span class="c1"># hash_size_cumsum[t + 1] - hash_size_cumsum[t]</span>
        <span class="n">hash_size_cumsum</span> <span class="o">=</span> <span class="p">[</span><span class="n">hash_size_cumsum</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">feature_table_map</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
            <span class="n">hash_size_cumsum</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;hash_size_cumsum&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">hash_size_cumsum</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="n">weights_offsets</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span>
            <span class="n">accumulate</span><span class="p">([</span><span class="n">row</span> <span class="o">*</span> <span class="n">dim</span> <span class="k">for</span> <span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="ow">in</span> <span class="n">embedding_specs</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
                <span class="n">weights_offsets</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">table_embedding_dtype</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">feature_table_map</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>
            <span class="n">row</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">embedding_specs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">weights_offsets</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="p">:</span> <span class="n">weights_offsets</span><span class="p">[</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
                <span class="o">!=</span> <span class="n">row</span> <span class="o">*</span> <span class="n">dim</span>
            <span class="p">):</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;row </span><span class="si">{</span><span class="n">row</span><span class="si">}</span><span class="s2"> dim </span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2"> feature </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2"> t </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">weights_offsets</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">weights_offsets</span><span class="p">[</span><span class="n">t</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">weights_offsets</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="p">:</span> <span class="n">weights_offsets</span><span class="p">[</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
                <span class="o">==</span> <span class="n">row</span> <span class="o">*</span> <span class="n">dim</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">hash_size_cumsum</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">==</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="n">row</span> <span class="k">for</span> <span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="n">embedding_specs</span><span class="p">[:</span><span class="n">t</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights_physical_offsets</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights_offsets</span>
        <span class="n">weights_offsets</span> <span class="o">=</span> <span class="p">[</span><span class="n">weights_offsets</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">feature_table_map</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="s2">&quot;weights_offsets&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">weights_offsets</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
            <span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">offsets</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">per_sample_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_requires_grad</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">offsets</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">fbgemm</span><span class="o">.</span><span class="n">dense_embedding_codegen_lookup_function</span><span class="p">(</span>
            <span class="n">dev_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span>
            <span class="n">weights_offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_offsets</span><span class="p">,</span>
            <span class="n">D_offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">D_offsets</span><span class="p">,</span>
            <span class="n">total_D</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">total_D</span><span class="p">,</span>
            <span class="n">max_D</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_D</span><span class="p">,</span>
            <span class="n">hash_size_cumsum</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_size_cumsum</span><span class="p">,</span>
            <span class="n">total_hash_size_bits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">total_hash_size_bits</span><span class="p">,</span>
            <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
            <span class="n">offsets</span><span class="o">=</span><span class="n">offsets</span><span class="p">,</span>
            <span class="n">pooling_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pooling_mode</span><span class="p">,</span>
            <span class="n">indice_weights</span><span class="o">=</span><span class="n">per_sample_weights</span><span class="p">,</span>
            <span class="n">feature_requires_grad</span><span class="o">=</span><span class="n">feature_requires_grad</span><span class="p">,</span>
            <span class="n">output_dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dtype</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
    <span class="k">def</span> <span class="nf">split_embedding_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a list of weights, split by table</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_specs</span><span class="p">):</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_physical_offsets</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
            <span class="n">splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">detach</span><span class="p">()[</span><span class="n">offset</span> <span class="p">:</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">dim</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">splits</span>

    <span class="k">def</span> <span class="nf">init_embedding_weights_uniform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">min_val</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">max_val</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_embedding_weights</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">:</span>
            <span class="n">param</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">)</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020 - 2024, FBGEMM Team.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/sphinx_highlight.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>