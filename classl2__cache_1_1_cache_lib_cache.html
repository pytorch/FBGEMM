<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>fbgemm_gpu: CacheLibCache Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">fbgemm_gpu
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>l2_cache</b></li><li class="navelem"><a class="el" href="classl2__cache_1_1_cache_lib_cache.html">CacheLibCache</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classl2__cache_1_1_cache_lib_cache-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">CacheLibCache Class Reference<div class="ingroups"><a class="el" href="group__embedding-ssd.html">Embedding SSD Operators</a></div></div></div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;cachelib_cache.h&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a282a9c139e4285f4d676e104846d6708" id="r_a282a9c139e4285f4d676e104846d6708"><td class="memItemLeft" align="right" valign="top">std::optional&lt; void * &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a282a9c139e4285f4d676e104846d6708">get</a> (int64_t key)</td></tr>
<tr class="separator:a282a9c139e4285f4d676e104846d6708"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acdafef20baf1a45ec1295ba332a065d1" id="r_acdafef20baf1a45ec1295ba332a065d1"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#acdafef20baf1a45ec1295ba332a065d1">get_shard_id</a> (int64_t key)</td></tr>
<tr class="separator:acdafef20baf1a45ec1295ba332a065d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35f4ec049ea4846946a6f6f2205b4280" id="r_a35f4ec049ea4846946a6f6f2205b4280"><td class="memItemLeft" align="right" valign="top">facebook::cachelib::PoolId&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a35f4ec049ea4846946a6f6f2205b4280">get_pool_id</a> (int64_t key)</td></tr>
<tr class="separator:a35f4ec049ea4846946a6f6f2205b4280"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28487224efe43ac3f96d4f03981a2f24" id="r_a28487224efe43ac3f96d4f03981a2f24"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a28487224efe43ac3f96d4f03981a2f24">batchMarkUseful</a> (const std::vector&lt; Cache::ReadHandle &gt; &amp;read_handles)</td></tr>
<tr class="separator:a28487224efe43ac3f96d4f03981a2f24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ee8139247e86b5cf6a52582c1ff5686" id="r_a9ee8139247e86b5cf6a52582c1ff5686"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9ee8139247e86b5cf6a52582c1ff5686">put</a> (int64_t key, const at::Tensor &amp;data)</td></tr>
<tr class="separator:a9ee8139247e86b5cf6a52582c1ff5686"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af34eef9d403b258ec310509fa65268a5" id="r_af34eef9d403b258ec310509fa65268a5"><td class="memItemLeft" align="right" valign="top">std::tuple&lt; at::Tensor, at::Tensor, at::Tensor &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af34eef9d403b258ec310509fa65268a5">get_all_items</a> ()</td></tr>
<tr class="separator:af34eef9d403b258ec310509fa65268a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c647623fef9959bd482911050ba9711" id="r_a7c647623fef9959bd482911050ba9711"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7c647623fef9959bd482911050ba9711">init_tensor_for_l2_eviction</a> (const at::Tensor &amp;indices, const at::Tensor &amp;weights, const at::Tensor &amp;count)</td></tr>
<tr class="separator:a7c647623fef9959bd482911050ba9711"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59d4800235bf477ae8b2da78001519dd" id="r_a59d4800235bf477ae8b2da78001519dd"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a59d4800235bf477ae8b2da78001519dd">reset_eviction_states</a> ()</td></tr>
<tr class="separator:a59d4800235bf477ae8b2da78001519dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a734581f1e255fb1521a8241c27a230c2" id="r_a734581f1e255fb1521a8241c27a230c2"><td class="memItemLeft" align="right" valign="top">folly::Optional&lt; std::tuple&lt; at::Tensor, at::Tensor, at::Tensor &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a734581f1e255fb1521a8241c27a230c2">get_tensors_and_reset</a> ()</td></tr>
<tr class="separator:a734581f1e255fb1521a8241c27a230c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>It is for maintaining all the cache related operations, including initialization, insertion, lookup and eviction. It is stateful for eviction logic that caller has to specifically fetch and reset eviction related states. Cachelib related optimization will be captured inside this class e.g. fetch and delayed markUseful to boost up get performance</p>
<dl class="section note"><dt>Note</dt><dd>that this class only handles single Cachelib read/update. parallelism is done on the caller side </dd></dl>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a28487224efe43ac3f96d4f03981a2f24" name="a28487224efe43ac3f96d4f03981a2f24"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a28487224efe43ac3f96d4f03981a2f24">&#9670;&#160;</a></span>batchMarkUseful()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void batchMarkUseful </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; Cache::ReadHandle &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>read_handles</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>update the LRU queue in cachelib, this is detached from cache-&gt;find() so that we could boost up the lookup perf without worrying about LRU queue contention</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">read_handles</td><td>the read handles that record what cache item has been accessed </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a282a9c139e4285f4d676e104846d6708" name="a282a9c139e4285f4d676e104846d6708"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a282a9c139e4285f4d676e104846d6708">&#9670;&#160;</a></span>get()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::optional&lt; void * &gt; get </td>
          <td>(</td>
          <td class="paramtype">int64_t</td>          <td class="paramname"><span class="paramname"><em>key</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Find the stored embeddings from a given embedding indices, aka key</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">key</td><td>embedding index to look up</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>an optional value, return none on cache misses, if cache hit return a pointer to the cachelib underlying storage of associated embeddings</dd></dl>
<dl class="section note"><dt>Note</dt><dd>that this is not thread safe, caller needs to make sure the data is fully processed before doing cache insertion, otherwise the returned space might be overwritten if cache is full </dd></dl>

</div>
</div>
<a id="af34eef9d403b258ec310509fa65268a5" name="af34eef9d403b258ec310509fa65268a5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af34eef9d403b258ec310509fa65268a5">&#9670;&#160;</a></span>get_all_items()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::tuple&lt; at::Tensor, at::Tensor, at::Tensor &gt; get_all_items </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>iterate through all items in L2 cache, fill them in indices and weights respectively and return indices, weights and count</p>
<dl class="section return"><dt>Returns</dt><dd>indices The 1D embedding index tensor, should skip on negative value </dd>
<dd>
weights The 2D tensor that each row(embeddings) is paired up with relative element in &lt;indices&gt; </dd>
<dd>
count A single element tensor that contains the number of indices to be processed</dd></dl>
<dl class="section note"><dt>Note</dt><dd>this isn't thread safe, caller needs to make sure put isn't called while this is executed. </dd></dl>

</div>
</div>
<a id="a35f4ec049ea4846946a6f6f2205b4280" name="a35f4ec049ea4846946a6f6f2205b4280"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a35f4ec049ea4846946a6f6f2205b4280">&#9670;&#160;</a></span>get_pool_id()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">facebook::cachelib::PoolId get_pool_id </td>
          <td>(</td>
          <td class="paramtype">int64_t</td>          <td class="paramname"><span class="paramname"><em>key</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>get pool id given an embedding index</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">key</td><td>embedding index to get pool id</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a pool id associated with the given key, this is to build a deterministic mapping from a embedding index to a specific pool id </dd></dl>

</div>
</div>
<a id="acdafef20baf1a45ec1295ba332a065d1" name="acdafef20baf1a45ec1295ba332a065d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acdafef20baf1a45ec1295ba332a065d1">&#9670;&#160;</a></span>get_shard_id()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">size_t get_shard_id </td>
          <td>(</td>
          <td class="paramtype">int64_t</td>          <td class="paramname"><span class="paramname"><em>key</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Cachelib wrapper specific hash function</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">key</td><td>embedding index to get hashed</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>an hashed value ranges from [0, num_pools) </dd></dl>

</div>
</div>
<a id="a734581f1e255fb1521a8241c27a230c2" name="a734581f1e255fb1521a8241c27a230c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a734581f1e255fb1521a8241c27a230c2">&#9670;&#160;</a></span>get_tensors_and_reset()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">folly::Optional&lt; std::tuple&lt; at::Tensor, at::Tensor, at::Tensor &gt; &gt; get_tensors_and_reset </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>get the filled indices and weights tensors from L2 eviction, could be all invalid if no eviction happened </p>

</div>
</div>
<a id="a7c647623fef9959bd482911050ba9711" name="a7c647623fef9959bd482911050ba9711"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7c647623fef9959bd482911050ba9711">&#9670;&#160;</a></span>init_tensor_for_l2_eviction()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void init_tensor_for_l2_eviction </td>
          <td>(</td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>indices</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>weights</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>count</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>instantiate eviction related indices and weights tensors(size of &lt;count&gt;) for L2 eviction using the same dtype and device from &lt;indices&gt; and &lt;weights&gt; , managed on the caller side</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">indices</td><td>The 1D embedding index tensor, should skip on negative value </td></tr>
    <tr><td class="paramname">weights</td><td>The 2D tensor that each row(embeddings) is paired up with relative element in &lt;indices&gt; </td></tr>
    <tr><td class="paramname">count</td><td>A single element tensor that contains the number of indices to be processed</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None </dd></dl>

</div>
</div>
<a id="a9ee8139247e86b5cf6a52582c1ff5686" name="a9ee8139247e86b5cf6a52582c1ff5686"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9ee8139247e86b5cf6a52582c1ff5686">&#9670;&#160;</a></span>put()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool put </td>
          <td>(</td>
          <td class="paramtype">int64_t</td>          <td class="paramname"><span class="paramname"><em>key</em>, </span></td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const at::Tensor &amp;</td>          <td class="paramname"><span class="paramname"><em>data</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Add an embedding index and embeddings into cachelib</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">key</td><td>embedding index to insert</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>true on success insertion, false on failure insertion, a failure insertion could happen if the refcount of bottom K items in LRU queue isn't 0. </dd></dl>
<dl class="section note"><dt>Note</dt><dd>In training use case, this is not expected to happen as we do bulk read and bluk write sequentially</dd>
<dd>
cache_-&gt;allocation will trigger eviction callback func </dd></dl>

</div>
</div>
<a id="a59d4800235bf477ae8b2da78001519dd" name="a59d4800235bf477ae8b2da78001519dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a59d4800235bf477ae8b2da78001519dd">&#9670;&#160;</a></span>reset_eviction_states()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void reset_eviction_states </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>reset slot pointer that points to the next available slot in the eviction tensors and returns number of slots filled </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>/__w/FBGEMM/FBGEMM/fbgemm_gpu/include/fbgemm_gpu/split_embeddings_cache/<b>cachelib_cache.h</b></li>
<li>/__w/FBGEMM/FBGEMM/fbgemm_gpu/src/split_embeddings_cache/<b>cachelib_cache.cpp</b></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0
</small></address>
</body>
</html>
