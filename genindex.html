


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Index &mdash; FBGEMM 0.6.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="#" />
    <link rel="search" title="Search" href="search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch">
                  <span class="dropdown-title">ExecuTorch</span>
                </a>
              </div>
            </div>  
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  0.6
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">General Info</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="general/Contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="general/documentation/Overview.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="general/ContactUs.html">Contact Us</a></li>
<li class="toctree-l1"><a class="reference internal" href="general/License.html">License</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="fbgemm-development/BuildInstructions.html">Build Instructions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM_GPU Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-development/BuildInstructions.html">Build Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-development/InstallationInstructions.html">Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-development/TestInstructions.html">Test Instructions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM_GPU Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-overview/jagged-tensor-ops/JaggedTensorOps.html">Jagged Tensor Operators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="fbgemm-cpp-api/QuantUtils.html">Quantization Utilities</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM_GPU C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-cpp-api/sparse_ops.html">Sparse Data Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-cpp-api/quantize_ops.html">Quantization Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-cpp-api/merge_pooled_embeddings.html">Pooled Embeddings Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html">Table Batched Embedding Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-cpp-api/jagged_tensor_ops.html">Jagged Tensor Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-cpp-api/memory_utils.html">CUDA Memory Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-cpp-api/input_combine.html">Combine Input Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-cpp-api/layout_transform_ops.html">Layout Transformation Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-cpp-api/embedding_ops.html">Embedding Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-cpp-api/experimental_ops.html">Experimental Operators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FBGEMM_GPU Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-python-api/table_batched_embedding_ops.html">Table Batched Embedding (TBE) Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="fbgemm_gpu-python-api/jagged_tensor_ops.html">Jagged Tensor Operators</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Index</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              

<h1 id="index">Index</h1>

<div class="genindex-jumpbox">
 <a href="#_"><strong>_</strong></a>
 | <a href="#A"><strong>A</strong></a>
 | <a href="#B"><strong>B</strong></a>
 | <a href="#D"><strong>D</strong></a>
 | <a href="#E"><strong>E</strong></a>
 | <a href="#F"><strong>F</strong></a>
 | <a href="#G"><strong>G</strong></a>
 | <a href="#H"><strong>H</strong></a>
 | <a href="#I"><strong>I</strong></a>
 | <a href="#J"><strong>J</strong></a>
 | <a href="#L"><strong>L</strong></a>
 | <a href="#M"><strong>M</strong></a>
 | <a href="#N"><strong>N</strong></a>
 | <a href="#P"><strong>P</strong></a>
 | <a href="#Q"><strong>Q</strong></a>
 | <a href="#R"><strong>R</strong></a>
 | <a href="#S"><strong>S</strong></a>
 | <a href="#T"><strong>T</strong></a>
 | <a href="#U"><strong>U</strong></a>
 | <a href="#X"><strong>X</strong></a>
 
</div>
<h2 id="_">_</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv422_bfloat16_to_float_gpuRKN2at6TensorE">_bfloat16_to_float_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv422_float_to_bfloat16_gpuRKN2at6TensorE">_float_to_bfloat16_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv424_float_to_FP8rowwise_gpuRK6TensorKb">_float_to_FP8rowwise_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv434_float_to_fused8bitrowwise_cpu_outR6TensorRK6Tensor">_float_to_fused8bitrowwise_cpu_out (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv430_float_to_fused8bitrowwise_gpuRK6Tensor">_float_to_fused8bitrowwise_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv430_float_to_fusednbitrowwise_gpuRK6TensorK7int64_t">_float_to_fusednbitrowwise_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv418_float_to_hfp8_gpuRKN2at6TensorEK7int64_tK7int64_tKd">_float_to_hfp8_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv418_float_to_msfp_gpuRKN2at6TensorEK7int64_tK7int64_tK7int64_tK7int64_tKdKd">_float_to_msfp_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv430_float_to_paddedFP8rowwise_gpuRK6TensorKbK7int64_t">_float_to_paddedFP8rowwise_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv424_FP8rowwise_to_float_gpuRKN2at6TensorEbK7int64_t">_FP8rowwise_to_float_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv434_fused8bitrowwise_to_float_cpu_outR6TensorRK6Tensor">_fused8bitrowwise_to_float_cpu_out (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv430_fused8bitrowwise_to_float_gpuRKN2at6TensorE">_fused8bitrowwise_to_float_gpu (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv440_fused8bitrowwise_to_float_mixed_dim_gpuRKN2at6TensorERKN2at6TensorEK7int64_t">_fused8bitrowwise_to_float_mixed_dim_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv429_fused8bitrowwise_to_half_gpuRKN2at6TensorE">_fused8bitrowwise_to_half_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv449_fused8bitrowwise_to_single_or_half_precision_gpuRKN2at6TensorEK7int64_tKbKb">_fused8bitrowwise_to_single_or_half_precision_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv430_fusednbitrowwise_to_float_gpuRKN2at6TensorEK7int64_t">_fusednbitrowwise_to_float_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv429_fusednbitrowwise_to_half_gpuRKN2at6TensorEK7int64_t">_fusednbitrowwise_to_half_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv449_fusednbitrowwise_to_single_or_half_precision_gpuRKN2at6TensorEK7int64_tK7int64_t">_fusednbitrowwise_to_single_or_half_precision_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv429_half_to_fused8bitrowwise_gpuRK6Tensor">_half_to_fused8bitrowwise_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv429_half_to_fusednbitrowwise_gpuRKN2at6TensorEK7int64_t">_half_to_fusednbitrowwise_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv418_hfp8_to_float_gpuRKN2at6TensorEK7int64_tK7int64_t">_hfp8_to_float_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv418_msfp_to_float_gpuRKN2at6TensorEK7int64_tK7int64_tK7int64_t">_msfp_to_float_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv430_paddedFP8rowwise_to_float_gpuRKN2at6TensorEKbK7int64_tK7int64_tK7int64_t">_paddedFP8rowwise_to_float_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv449_single_or_half_precision_to_fused8bitrowwise_gpuRK6Tensor">_single_or_half_precision_to_fused8bitrowwise_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv449_single_or_half_precision_to_fusednbitrowwise_gpuRK6TensorK7int64_t">_single_or_half_precision_to_fusednbitrowwise_gpu (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="A">A</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/merge_pooled_embeddings.html#_CPPv417all_to_one_deviceNSt6vectorIN2at6TensorEEEN2at6DeviceE">all_to_one_device (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="B">B</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/jagged_tensor_ops.html#_CPPv431batched_dense_vec_jagged_2d_mulRK6TensorRK6TensorRK6Tensor">batched_dense_vec_jagged_2d_mul (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-python-api/jagged_tensor_ops.html#torch.ops.fbgemm.batched_dense_vec_jagged_2d_mul">batched_dense_vec_jagged_2d_mul() (in module torch.ops.fbgemm)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/embedding_ops.html#_CPPv425bounds_check_indices_cudaR6TensorR6TensorR6Tensor7int64_tR6TensorRKN3c108optionalI6TensorEERKN3c108optionalI6TensorEEK7int64_t">bounds_check_indices_cuda (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="D">D</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/jagged_tensor_ops.html#_CPPv415dense_to_jaggedRK6TensorRKNSt6vectorI6TensorEEN3c108optionalIN2at6SymIntEEE">dense_to_jagged (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-python-api/jagged_tensor_ops.html#torch.ops.fbgemm.dense_to_jagged">dense_to_jagged() (in module torch.ops.fbgemm)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv442direct_mapped_lru_cache_populate_byte_cudaN2at6TensorEN2at6TensorE7int64_tN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorE7int64_tN2at6TensorEN2at6TensorE7int64_tbN3c108optionalIN2at6TensorEEE">direct_mapped_lru_cache_populate_byte_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv435direct_mapped_lxu_cache_lookup_cudaN2at6TensorEN2at6TensorE7int64_tbN3c108optionalIN2at6TensorEEE">direct_mapped_lxu_cache_lookup_cuda (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="E">E</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="general/documentation/Cpp.html#_CPPv4I0_NSt6size_tEE14example_method7int32_t1Tf">example_method (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="general/documentation/Python.html#fbgemm_gpu.docs.examples.example_method">example_method() (in module fbgemm_gpu.docs.examples)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/sparse_ops.html#_CPPv431expand_into_jagged_permute_cudaRKN2at6TensorERKN2at6TensorERKN2at6TensorE7int64_t">expand_into_jagged_permute_cuda (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="F">F</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li>
    fbgemm_gpu

      <ul>
        <li><a href="fbgemm_gpu-python-api/table_batched_embedding_ops.html#module-fbgemm_gpu">module</a>
</li>
      </ul></li>
      <li><a href="fbgemm-cpp-api/QuantUtils.html#_CPPv410FindMinMaxPKfPfPf7int64_t">FindMinMax (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv437float_or_half_to_fused8bitrowwise_cpuRK6Tensor">float_or_half_to_fused8bitrowwise_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv423float_to_FP8rowwise_cpuRK6Tensorb">float_to_FP8rowwise_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv429float_to_fused8bitrowwise_cpuRK6Tensor">float_to_fused8bitrowwise_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm-cpp-api/QuantUtils.html#_CPPv4I0E44FloatOrHalfToFusedNBitRowwiseQuantizedSBHalfviPK9InputType6size_tiPNSt7uint8_tE">FloatOrHalfToFusedNBitRowwiseQuantizedSBHalf (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv423FloatToFP8Quantized_refPCKfK6size_tK6size_tPC7uint8_tKiKiKd">FloatToFP8Quantized_ref (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv423FP8QuantizedToFloat_refPCK7uint8_tK6size_tK6size_tPCfKiKi">FP8QuantizedToFloat_ref (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv423FP8rowwise_to_float_cpuRK6TensorbK7int64_t">FP8rowwise_to_float_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv429fused8bitrowwise_to_float_cpuRK6Tensor">fused8bitrowwise_to_float_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv437fused8bitrowwise_to_float_or_half_cpuRK6TensorK7int64_tKbKb">fused8bitrowwise_to_float_or_half_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv428fused8bitrowwise_to_half_cpuRK6Tensor">fused8bitrowwise_to_half_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv429fusednbitrowwise_to_float_cpuRK6TensorK7int64_t">fusednbitrowwise_to_float_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv437fusednbitrowwise_to_float_or_half_cpuRK6TensorK7int64_tK7int64_t">fusednbitrowwise_to_float_or_half_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv428fusednbitrowwise_to_half_cpuRK6TensorK7int64_t">fusednbitrowwise_to_half_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm-cpp-api/QuantUtils.html#_CPPv4I0E23FusedQuantizeDequantizevPKfPfNSt7int64_tERK24TensorQuantizationParamsiif">FusedQuantizeDequantize (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="G">G</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/sparse_ops.html#_CPPv452generic_histogram_binning_calibration_by_feature_cpuRKN2at6TensorERKN2at6TensorERKN2at6TensorE7int64_tRKN2at6TensorERKN2at6TensorERKN2at6TensorEd7int64_td">generic_histogram_binning_calibration_by_feature_cpu (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv423get_unique_indices_cudaN2at6TensorE7int64_tb">get_unique_indices_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/experimental_ops.html#_CPPv415gqa_attn_splitkRKN2at6TensorERKN2at6TensorERKN2at6TensorERKN2at6TensorEKdK7int64_tK7int64_tKb">gqa_attn_splitk (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="H">H</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/quantize_ops.html#_CPPv428half_to_fused8bitrowwise_cpuRK6Tensor">half_to_fused8bitrowwise_cpu (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/sparse_ops.html#_CPPv433histogram_binning_calibration_cpuRKN2at6TensorERKN2at6TensorERKN2at6TensorEddd7int64_td">histogram_binning_calibration_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv419host_lxu_cache_slot7int64_t7int64_t">host_lxu_cache_slot (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="I">I</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/embedding_ops.html#_CPPv448int_nbit_split_embedding_codegen_lookup_function6Tensor6Tensor6Tensor6Tensor6Tensor6Tensor7int64_t7int64_t7int64_t7int64_t7int64_t7int64_t6Tensor6Tensor7int64_tN3c108optionalI6TensorEE7int64_tN3c108optionalI6TensorEEN3c108optionalI6TensorEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEE">int_nbit_split_embedding_codegen_lookup_function (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/embedding_ops.html#_CPPv452int_nbit_split_embedding_codegen_lookup_function_cpu6Tensor6Tensor6Tensor6Tensor6Tensor6Tensor7int64_t7int64_t7int64_t7int64_t7int64_t7int64_t6Tensor6Tensor7int64_tN3c108optionalI6TensorEE7int64_tN3c108optionalI6TensorEEN3c108optionalI6TensorEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEE">int_nbit_split_embedding_codegen_lookup_function_cpu (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/embedding_ops.html#_CPPv460int_nbit_split_embedding_uvm_caching_codegen_lookup_function6Tensor6Tensor6Tensor6Tensor6Tensor6Tensor7int64_t7int64_t7int64_t7int64_t7int64_t7int64_t6Tensor6Tensor7int64_tN3c108optionalI6TensorEE7int64_tN3c108optionalI6TensorEEN3c108optionalI6TensorEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEEN3c108optionalI6TensorEEN3c108optionalI7int64_tEEN3c108optionalI6TensorEEN3c108optionalI6TensorEEN3c108optionalI6TensorEE">int_nbit_split_embedding_uvm_caching_codegen_lookup_function (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/embedding_ops.html#_CPPv464int_nbit_split_embedding_uvm_caching_codegen_lookup_function_cpu6Tensor6Tensor6Tensor6Tensor6Tensor6Tensor7int64_t7int64_t7int64_t7int64_t7int64_t7int64_t6Tensor6Tensor7int64_tN3c108optionalI6TensorEE7int64_tN3c108optionalI6TensorEEN3c108optionalI6TensorEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEEN3c108optionalI7int64_tEEN3c108optionalI6TensorEEN3c108optionalI7int64_tEEN3c108optionalI6TensorEEN3c108optionalI6TensorEEN3c108optionalI6TensorEE">int_nbit_split_embedding_uvm_caching_codegen_lookup_function_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv413is_uvm_tensorRK6Tensor">is_uvm_tensor (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="J">J</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/jagged_tensor_ops.html#_CPPv418jagged_1d_to_dense6Tensor6TensorN3c106SymIntE7int64_t">jagged_1d_to_dense (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-python-api/jagged_tensor_ops.html#torch.ops.fbgemm.jagged_1d_to_dense">jagged_1d_to_dense() (in module torch.ops.fbgemm)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/jagged_tensor_ops.html#_CPPv418jagged_2d_to_dense6Tensor6TensorN3c106SymIntE">jagged_2d_to_dense (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-python-api/jagged_tensor_ops.html#torch.ops.fbgemm.jagged_2d_to_dense">jagged_2d_to_dense() (in module torch.ops.fbgemm)</a>
</li>
      <li><a href="fbgemm_gpu-python-api/jagged_tensor_ops.html#torch.ops.fbgemm.jagged_dense_dense_elementwise_add_jagged_output">jagged_dense_dense_elementwise_add_jagged_output() (in module torch.ops.fbgemm)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/jagged_tensor_ops.html#_CPPv428jagged_dense_elementwise_addRK6TensorRKNSt6vectorI6TensorEERK6Tensor">jagged_dense_elementwise_add (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-python-api/jagged_tensor_ops.html#torch.ops.fbgemm.jagged_dense_elementwise_add">jagged_dense_elementwise_add() (in module torch.ops.fbgemm)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/jagged_tensor_ops.html#_CPPv442jagged_dense_elementwise_add_jagged_outputRK6TensorRKNSt6vectorI6TensorEERK6Tensor">jagged_dense_elementwise_add_jagged_output (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-python-api/jagged_tensor_ops.html#torch.ops.fbgemm.jagged_dense_elementwise_add_jagged_output">jagged_dense_elementwise_add_jagged_output() (in module torch.ops.fbgemm)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/jagged_tensor_ops.html#_CPPv447jagged_dense_elementwise_add_jagged_output_cudaRK6TensorRKNSt6vectorI6TensorEERK6Tensor">jagged_dense_elementwise_add_jagged_output_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/jagged_tensor_ops.html#_CPPv428jagged_dense_elementwise_mulRK6TensorRKNSt6vectorI6TensorEERK6Tensor">jagged_dense_elementwise_mul (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-python-api/jagged_tensor_ops.html#torch.ops.fbgemm.jagged_dense_elementwise_mul">jagged_dense_elementwise_mul() (in module torch.ops.fbgemm)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/jagged_tensor_ops.html#_CPPv422jagged_to_padded_denseRK6TensorRKNSt6vectorI6TensorEEKN3c1014SymIntArrayRefEKd">jagged_to_padded_dense (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-python-api/jagged_tensor_ops.html#torch.ops.fbgemm.jagged_to_padded_dense">jagged_to_padded_dense() (in module torch.ops.fbgemm)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/jagged_tensor_ops.html#_CPPv430jagged_to_padded_dense_forwardRK6TensorRKNSt6vectorI6TensorEEN3c1014SymIntArrayRefEKd">jagged_to_padded_dense_forward (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="L">L</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv428lfu_cache_populate_byte_cudaN2at6TensorEN2at6TensorE7int64_tN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorE7int64_t">lfu_cache_populate_byte_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv423lfu_cache_populate_cudaN2at6TensorEN2at6TensorE7int64_tN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEb">lfu_cache_populate_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv428linearize_cache_indices_cudaRKN2at6TensorERKN2at6TensorERKN2at6TensorERKN3c108optionalIN2at6TensorEEEK7int64_t">linearize_cache_indices_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv441linearize_cache_indices_from_row_idx_cudaN2at6TensorEN2at6TensorEN2at6TensorE">linearize_cache_indices_from_row_idx_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv428lru_cache_find_uncached_cudaN2at6TensorEN2at6TensorE7int64_tN2at6TensorE7int64_tN2at6TensorEbN2at6TensorEbN2at6TensorE">lru_cache_find_uncached_cuda (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv428lru_cache_populate_byte_cudaN2at6TensorEN2at6TensorE7int64_tN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorE7int64_tN2at6TensorE7int64_tbN3c108optionalIN2at6TensorEEE">lru_cache_populate_byte_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv423lru_cache_populate_cudaN2at6TensorEN2at6TensorE7int64_tN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorE7int64_tN2at6TensorEbbN3c108optionalIN2at6TensorEEEbN3c108optionalIN2at6TensorEEE">lru_cache_populate_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv420lxu_cache_flush_cudaN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorE7int64_tN2at6TensorEN2at6TensorEb">lxu_cache_flush_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv431lxu_cache_locations_update_cudaN2at6TensorEN2at6TensorEN3c108optionalIN2at6TensorEEE">lxu_cache_locations_update_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv440lxu_cache_locking_counter_decrement_cudaN2at6TensorEN2at6TensorE">lxu_cache_locking_counter_decrement_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv421lxu_cache_lookup_cudaN2at6TensorEN2at6TensorE7int64_tbN3c108optionalIN2at6TensorEEEN3c108optionalIN2at6TensorEEEN3c108optionalIN2at6TensorEEE">lxu_cache_lookup_cuda (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="M">M</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li>
    module

      <ul>
        <li><a href="fbgemm_gpu-python-api/table_batched_embedding_ops.html#module-fbgemm_gpu">fbgemm_gpu</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="N">N</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv422new_host_mapped_tensorRK6TensorRKNSt6vectorINSt7int64_tEEE">new_host_mapped_tensor (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv418new_managed_tensorRK6TensorRKNSt6vectorINSt7int64_tEEE">new_managed_tensor (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv423new_managed_tensor_metaRK6TensorRKNSt6vectorINSt7int64_tEEE">new_managed_tensor_meta (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv418new_unified_tensorRK6TensorRKNSt6vectorINSt7int64_tEEEb">new_unified_tensor (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv426new_vanilla_managed_tensorRK6TensorRKNSt6vectorINSt7int64_tEEE">new_vanilla_managed_tensor (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="P">P</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/input_combine.html#_CPPv435padding_fused_tbe_input_combine_cpuRKNSt6vectorIN2at6TensorEEERKNSt6vectorIN2at6TensorEEERKNSt6vectorIN2at6TensorEEERKN2at6TensorE7int64_t">padding_fused_tbe_input_combine_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/merge_pooled_embeddings.html#_CPPv429permute_pooled_embs_auto_gradRK6TensorRK6TensorRK6TensorRK6TensorRK6Tensor">permute_pooled_embs_auto_grad (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/merge_pooled_embeddings.html#_CPPv433permute_pooled_embs_auto_grad_cpuRK6TensorRK6TensorRK6TensorRK6TensorRK6Tensor">permute_pooled_embs_auto_grad_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/merge_pooled_embeddings.html#_CPPv433permute_pooled_embs_auto_grad_gpuRK6TensorRK6TensorRK6TensorRK6TensorRK6Tensor">permute_pooled_embs_auto_grad_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/merge_pooled_embeddings.html#_CPPv439permute_pooled_embs_auto_grad_split_cpuRKN2at6TensorERKN2at6TensorERKN2at6TensorERKN2at6TensorERKN2at6TensorE">permute_pooled_embs_auto_grad_split_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/merge_pooled_embeddings.html#_CPPv439permute_pooled_embs_auto_grad_split_gpuRKN2at6TensorERKN2at6TensorERKN2at6TensorERKN2at6TensorERKN2at6TensorE">permute_pooled_embs_auto_grad_split_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/merge_pooled_embeddings.html#_CPPv428permute_pooled_embs_cpu_implRKN2at6TensorERKN2at6TensorERKN2at6TensorERKN2at6TensorERKN2at6TensorERKb">permute_pooled_embs_cpu_impl (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/merge_pooled_embeddings.html#_CPPv429permute_pooled_embs_split_cpuRKN2at6TensorERKN2at6TensorERKN2at6TensorERKN2at6TensorERKN2at6TensorE">permute_pooled_embs_split_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/merge_pooled_embeddings.html#_CPPv429permute_pooled_embs_split_gpuRKN2at6TensorERKN2at6TensorERKN2at6TensorERKN2at6TensorERKN2at6TensorE">permute_pooled_embs_split_gpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/embedding_ops.html#_CPPv423pruned_array_lookup_cpu6Tensor6Tensor6Tensor6Tensor">pruned_array_lookup_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/embedding_ops.html#_CPPv424pruned_array_lookup_cuda6Tensor6Tensor6Tensor6Tensor">pruned_array_lookup_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/embedding_ops.html#_CPPv436pruned_hashmap_insert_unweighted_cpu6Tensor6Tensor6Tensor6Tensor6Tensor">pruned_hashmap_insert_unweighted_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/embedding_ops.html#_CPPv426pruned_hashmap_lookup_cuda6Tensor6Tensor6Tensor6Tensor">pruned_hashmap_lookup_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/embedding_ops.html#_CPPv436pruned_hashmap_lookup_unweighted_cpu6Tensor6Tensor6Tensor6Tensor">pruned_hashmap_lookup_unweighted_cpu (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="Q">Q</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm-cpp-api/QuantUtils.html#_CPPv4I0_8layout_tE17QuantizeGroupwisevPKfiiiiPKfPKNSt7int32_tEP1T">QuantizeGroupwise (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="R">R</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/layout_transform_ops.html#_CPPv432recat_embedding_grad_output_cuda6TensorRKNSt6vectorI7int64_tEE">recat_embedding_grad_output_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/layout_transform_ops.html#_CPPv446recat_embedding_grad_output_mixed_D_batch_cudaRK6TensorRK6TensorRK6Tensor">recat_embedding_grad_output_mixed_D_batch_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/layout_transform_ops.html#_CPPv439recat_embedding_grad_output_mixed_D_cpuRK6TensorRKNSt6vectorI7int64_tEE">recat_embedding_grad_output_mixed_D_cpu (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/layout_transform_ops.html#_CPPv440recat_embedding_grad_output_mixed_D_cudaRK6TensorRKNSt6vectorI7int64_tEE">recat_embedding_grad_output_mixed_D_cuda (C++ function)</a>
</li>
      <li><a href="fbgemm-cpp-api/QuantUtils.html#_CPPv4I_b_b_23QuantizationGranularity_b_b0_bE30requantizeOutputProcessingAvx2vPNSt7uint8_tEPKNSt7int32_tERK12block_type_tiiRK22requantizationParams_tI9BIAS_TYPEE">requantizeOutputProcessingAvx2 (C++ function)</a>
</li>
      <li><a href="fbgemm-cpp-api/QuantUtils.html#_CPPv4I_b_b_23QuantizationGranularity_b_b_i0E37requantizeOutputProcessingGConvAvx512vPNSt7uint8_tEPKNSt7int32_tERK12block_type_tiiRK22requantizationParams_tI9BIAS_TYPEE">requantizeOutputProcessingGConvAvx512 (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/split_table_batched_embeddings.html#_CPPv426reset_weight_momentum_cudaN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorEN2at6TensorE7int64_t">reset_weight_momentum_cuda (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="S">S</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-python-api/table_batched_embedding_ops.html#fbgemm_gpu.split_table_batched_embeddings_ops.SplitTableBatchedEmbeddingBagsCodegen">SplitTableBatchedEmbeddingBagsCodegen() (in module fbgemm_gpu.split_table_batched_embeddings_ops)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-python-api/jagged_tensor_ops.html#torch.ops.fbgemm.stacked_jagged_1d_to_dense">stacked_jagged_1d_to_dense() (in module torch.ops.fbgemm)</a>
</li>
      <li><a href="fbgemm_gpu-python-api/jagged_tensor_ops.html#torch.ops.fbgemm.stacked_jagged_2d_to_dense">stacked_jagged_2d_to_dense() (in module torch.ops.fbgemm)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="T">T</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/input_combine.html#_CPPv421tbe_input_combine_cpuRKNSt6vectorIN2at6TensorEEERKNSt6vectorIN2at6TensorEEERKNSt6vectorIN2at6TensorEEERKN2at6TensorE">tbe_input_combine_cpu (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="U">U</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv419uvm_cuda_mem_adviseRK6Tensor7int64_t">uvm_cuda_mem_advise (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv427uvm_cuda_mem_prefetch_asyncRK6TensorN3c108optionalI6TensorEE">uvm_cuda_mem_prefetch_async (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv424uvm_mem_advice_dont_forkRK6Tensor">uvm_mem_advice_dont_fork (C++ function)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv411uvm_storageRK6Tensor">uvm_storage (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv410uvm_to_cpuRK6Tensor">uvm_to_cpu (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv416uvm_to_cpu_cloneRK6Tensor">uvm_to_cpu_clone (C++ function)</a>
</li>
      <li><a href="fbgemm_gpu-cpp-api/memory_utils.html#_CPPv413uvm_to_deviceRK6TensorRK6Tensor">uvm_to_device (C++ function)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="X">X</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="fbgemm-cpp-api/QuantUtils.html#_CPPv46Xor128v">Xor128 (C++ function)</a>
</li>
  </ul></td>
</tr></table>



             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020 - 2024, FBGEMM Team.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/sphinx_highlight.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>